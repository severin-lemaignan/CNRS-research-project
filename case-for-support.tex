
\chapter{Research project}\label{part1}

\section{Long-term vision and ground-breaking nature of the project}

\begin{framed}

\noindent\bf This research project is about designing and
delivering a ground-breaking embodied AI for socially intelligent robots, with
long-term social utility and demonstrated acceptance in the real world.

\vspace{0.4em}
\noindent This breakthrough is made possible by a combination of novel methodologies and
the principled integration of complex socio-cognitive capabilities:

\begin{itemize}
        \item crowd-sourced social interaction patterns;
        \item `public-in-the-loop' machine learning;
        \item a novel spatio-temporal and social model of the robot's environment;
        \item novel, non-repetitive, social behaviour production based on
            generative neural networks;
        \item and finally, an integrative cognitive architecture, driven by
            long-term social goals.
\end{itemize}


\vspace{0.4em}
\noindent In addition, I will deliver the conceptual and ethical framework
required to further support the public debate and policy making process
around social robots, and concretely demonstrate lifescale applications of
this technology with ambitious, long-term deployments of autonomous robots
in high impact, social environments.


\vspace{0.4em}
\noindent The Laboratoire d'Analyse et d'Architecture des Syst√®mes (LAAS), part
of the Artificial and Natural Intelligence Toulouse Institute (ANITI), would
be an ideal host laboratory to successfully conduct this programme: its
strong track-record in autonomous interactive robots, combined with the breadth
of expertise available within the ANITI institute, would prove instrumental in
scaffolding and accelerating several of the key science breakthrough I target
with this project.

\vspace{0.4em}
\noindent Closely aligned with the national and European research priorities (see
\emph{National and International Importance} section), this research project
creates a unique opportunity to establish myself a key leader in Intelligent
Social Robotics, as well as asserting the CNRS and European worldwide
leadership in AI and robotics.

\end{framed}

\subsection{State of the art: real-world social robots and impact on the
society}

Social robotics is a disruptive field, with a profound impact on society and
economy~\parencite{williams2020social}. A recent report from the United Nations about
the impact of the technological revolution on labour markets stated that AI and
robotics are expected to radically change the labor market world-wide destroying
some job categories and creating others~\parencite{bruckner2017frontier}. Social
robotics, however, is still an young, emerging, research-active field. The
expectations are high, in multiple application domains: elderly care, customer
service (in airports and shopping malls, for instance), education, child
development, and autonomous vehicles to name a few~\parencite{baillie2019challenges}.
However, whereas both computer-based AI applications, and traditional industrial
robots already have a significant economic impact, social robots have not
reached that point yet. Significantly, the recent failures of several companies
investing in social robotics, like Jibo, Kuri, Willow Garage and Anki, and the
major setbacks of companies like SoftBank, who designed and deployed hundreds of
Pepper robot in their shops, before renouncing a few months later due to the poor
reception by the customers, show that these technologies are not yet
mature~\parencite{tulli2019great}.

Indeed, understanding \emph{why} these robots have failed, is one of the
active debate within the Human-Robot Interaction
community~\parencite{hoffman2019anki}, with only a handful of qualitative studies on
this question~\parencite{dereshev2019longterm,degraaf2017phased}. Proposed
explanations include the lack of perceived usefulness (robot seen purely as a
toy); the limited liveliness of the robot that become rapidly predictable and
repetitive~\parencite{lemaignan2014cognitive}; the poor management of expectations,
where user over-ascribe cognitive capabilities that do not match the reality.
The community agrees however that the crux of the issue is achieving long-term
social engagement~\parencite{yang2018grand,hoffman2019anki}

Research is however seemingly hitting a wall to further progress towards
socially meaningful long-term interactions. For instance, in their large review
of research in robotics for education, Belpaeme et al.~\parencite{belpaeme2018social}
point to the shortcomings that prevent further development of effective,
long-term social robotics in educative settings: the need for a correct
interpretation of the social environment; the difficulty of action selection;
the difficulty of pacing generated behaviours: three issues that underpin
long-term engagement.

Attempts at long-term human-robot interactions are nevertheless becoming more
common~\parencite{kunze2018artificial,leite2013social}, with a number of studies
involving social robots deployed in real-world settings (for instance in
schools~\parencite{leite2014empathic,westlund2017measuring,
lemaignan2016learning,coninx2016towards}, homes~\parencite{degraaf2017phased} and
care centres~\parencite{hawes2017strands,winkle2020couch}) over relatively long
periods of time (up to 2 or 3 months at a time). Even though these robots are
typically not fully autonomous, they do exhibit a level of autonomy, either by
handling autonomously a relatively broad range of shallow tasks (eg, a
butler-like robot answering simple questions, like in~\parencite{hawes2017strands} or
in the H2020 MuMMer~\parencite{heikkila2018can} and FP7
Spencer~\parencite{triebel2016spencer} projects), or a narrow, well-specified complex
task (for instance, supporting exercising in a gym, as I did in~\parencite{winkle2020couch}).
However, general purpose, long-term interaction is still an open question.


\subsection{Novely, context, timeliness, relevance}

The service and companion robots that we are set to interact with in the coming
years are being designed and built today in labs and startups all over the
world. Indeed, we already envision close and long-term human-robot interactions
in a range of sensitive domains like education, elderly care and health care.
Critically, we as a society, need to develop in parallel the underpinning
principles that will ensure the future roles of social robots are collectively
defined, in a responsible and ethical manner -- in particular in the context
their interactions with vulnerable populations.

\ul{Progressing this question requires real-world evidence}. However, because
autonomous social robots lie at the forward edge of science and engineering, the
real-world, long-term deployments required to gather such evidence are extremely
rare. As a consequence, we currently have limited insights into the factors that
determine the utility and acceptability of social robots.

\project approaches this important and timely question in a \textbf{novel and
ambitious} manner: the project will define and implement \textbf{a vision of AI
and social robotics that places the human at the centre of these emerging
technologies, to foster novel social dynamics that are acceptable and beneficial
to society}.I propose to create a \textbf{state-of-the-art autonomous social
robot} that not only learns social behaviours \textbf{with and from} the public
and end-users, but is also \textbf{co-designed from the ground-up to be
acceptable, responsible and useful} to the humans it will serve.

%In other words, \project seeks to answer \textbf{why
%would we want to embed social robots in our society?}, and \textbf{how to do
%so?}, from a technology and Responsible AI perspective.


%\begin{wrapfigure}[9]{r}{0.35\linewidth}
%    \centering
%    \vspace{-7pt}
%    \includegraphics[width=\linewidth]{concept.pdf}
%    \label{fig|concept}
%\end{wrapfigure}


\subsection{Ambition, adventure, transformative aspects}

This research is ground-breaking: \textbf{This resaerch programme will lead to
the design, implementation and real-world demonstration of the AI engine of a
socially-intelligent robot.  My aim is to create, sustain and better understand
the dynamics of responsible long-term social human-robot interactions, in order
to build robots that (1) have an effective, demonstrable social utility, and (2)
will see long-term acceptance by their end-users}.

%\textbf{This has not been done before}, and \textbf{from healthcare to manufacturing
%4.0, this result will have a major impact on our digital future, far beyond the
%boundaries of the project}.

The project is \textbf{ambitious}: in the next 5 to 10 years, I will have
brought together two emerging AI paradigms (teleological architectures and
human-in-the-loop machine learning); I will have them integrated into a
state-of-the-art cognitive architecture for autonomous social robots, relying on
multidisciplinary approaches where relevant (eg. a choreographer to create a
novel 'body language' for social robots); I will have created the conditions for
a unique, large-scale, `public-in-the-loop' participatory design approach that
will transform how we think about public engagement with technology design;
finally, I will have deployed co-designed autonomous robots in several
real-world, highly social settings, for significant periods of time.

Combining scientific ambition, engineering ambition and methodological ambition,
my research programme sets a high bar for excellence, which leads to a fourth
ambition: establishing myself as one of the key leaders in social robotics.
Surprisingly few groups worldwide have achieved full autonomy for a complex
social robot -- the LAAS is one of them.

By joining the laboratory, I would create the conditions to 'future-proof' this
scientific know-how, while developing a wide-ranging set of new research
directions that promise to have a transformative impact on our digital future.


\section{Methodology and approach to achieve impact}

The overall aim of my research programme is to \textbf{create, sustain and better
understand the dynamics of responsible, long-term social human-robot
interactions}. This translates into three overarching, long-term research questions:

\paragraph{\bf RQ1:} What are the public expectations with respect to the role
of social robots, and how can we collectively design principles ensuring
responsible, beneficial, socially acceptable robots?

\paragraph{\bf RQ2:} What are the conceptual, algorithmic and technical
prerequisites to design and implement such an embodied AI? in particular, what
AI is required to \textbf{sustain long-term engagement} between
end-users and a robot?

\paragraph{\bf RQ3:} What new ethical questions are raised by long-term social
interaction with an artificial agent, and in particular, how to balance
\textbf{autonomy} of the robot with \textbf{behaviour transparency} and
\textbf{human oversight}?

\vspace{0.5em}
\noindent From these questions, I derive the following five objectives that are
the guiding principles of my research programme:

\paragraph{\bf O1: conceptual framing} To construct a solid conceptual framing
around the multidisciplinary question of responsible human-robot interactions,
answering questions like: What should motivate the robot to step in
and attempt to help? or: What social norms are applicable to the robot behaviours? I
will investigate the basic principles of responsible social interactions, that
must form the foundations of a socially useful robot, accepted and used in the
long run.  Using user-centred design and participatory design methodologies, I
will identify the determinants and parameters of a responsible social
intervention, performed by a socially-driven robot, and formalise them in
guidelines.

\paragraph{\bf O2: real-time social modeling} To create the novel cognitive
capability of artificial \emph{social situation assessment} and enabe the
robot to represent real-time social dynamics in its environment, I will
significantly extend and integrate the current state-of-art in spatio-temporal
modeling (so-called \emph{situation assessment}) with my recent research in social
state modeling.

\paragraph{\bf O3: congruent social behaviours production} 
To create a novel way of producing non-repetitive, socially-congruent,
expressive motions using the state of the art in generative neural networks,
combined with data acquired from an expert choreographer. This will be
integrated with novel \emph{sound landscapes} to create a beyond-state-of-art,
non-verbal (yet highly expressive) action and communication system for the
robot.

\paragraph{\bf O4: embodied AI breakthrough} To create robot behaviours that are
perceived as purposeful and intentional (long-term goals), while being shaped by
a user-created and user-controlled action policy. I will integrate long-term
social goals, arising from the interaction principles of \textbf{O1}, with the
social modeling capability of \textbf{O2} and the behaviours production of
\textbf{O3} into a principled, goal-driven cognitive architecture. The
breakthrough will come from combining these long-term social goals with
bottom-up action policies, designed and learnt from the end-users using
human-in-the-loop reinforcement learning.

I want to specifically test the following two hypotheses: first, that long-term
social goals, if suitably co-designed with the public and stakeholders and
properly integrated into the robot as a \emph{social teleology}, will create the
perception that the robot is intentional and purposeful. This will in turn
elicit sustained engagement from its human users.

Second, that human-in-the-loop machine learning can
be used to ensure an additional layer of human oversight and a level of
behavioural transparency.  Human-in-the-loop reinforcement learning -- as
implemented in the SPARC approach that I have developed and already used in
complex social
environments~\parencite{senft2017supervised,senft2019teaching,winkle2020insitu}
-- relies on an end-user `teacher'. This teacher initially fully controls the
robot (via teleoperation) while it learns the action policy, and then
progressively relinquishes control up to a point where the robot is effectively
autonomous. As I previsouly argued~\parencite{senft2019teaching}, this approach
leads to increased control and ownership of the system, and as a result,
increased trust on the part of end-users.

This objective also raises one additional question: how to \emph{arbitrate}
between a top-down action policy arising from the long-term goals and the
bottom-up action policy learnt from the end-users? This question leads to
objective {\bf O4'}: To design a policy arbitration mechanism that preserves the
robot's long-term intentional behaviour while effectively guaranteeing human
control, ownership and oversight.

\paragraph{\bf O5: ambitious field research} Finally, the last major objective
of my research project is to demonstrate the effectiveness of my approach in
complex, real-world conditions. This means deploying the socially interactive
robots in existing social eco-systems that are sufficiently complex and open to
explore novel social interactions. My objective is also to show that this
real-world deployment can be successfully driven by the `end-to-end' involvement
of all the end-users and stakeholders: from defining the robot's role, from the
different perspective of each end-user, to actually designing and `teaching' the
robot what to do.

\begin{framed}

\noindent\bf Together, these five objectives build a coherent and realistic
pathway towards addressing the overall aim of my research programme:
creating, sustaining and better understanding the dynamics of responsible
long-term social human-robot interactions.

\end{framed}



%Two paradigms form the scientific backbone of the project: (1) for end-users to
%ascribe social utility and engage with the robot over long periods of time
%(months, years), the robot has to have its own long-term internal motivation to
%be socially helpful -- what we call a \emph{social teleology}; (2) long-term
%acceptance requires the genuine involvement of end-users at every step of the
%design process, so that they take \emph{ownership} of the technology --
%human-in-the-loop machine learning offers a promissing way forward, by
%permitting to design robot behaviours that genuinely originate from the
%end-users themselves.



%How this general
%principle translates into specific guidelines and algorithms -- while taking into
%account the principles of a responsible AI -- is the central
%contribution of Work Package 1.

% This socially-driven goal forms what we call a \emph{social
%teleology}. its own goals have this objective can only be achieved if the
%robot is \textbf{socially-driven}: the robot's behaviours must be driven by the
%intention to support positive human-human interactions. 


%I frame these principles within the broader concept of \textbf{robot-supported human-human
%interactions}, a novel conceptual framework to make it possible to `think' the future human-robot
%interactions at the societal level. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implementation of the work programme}

The five scientific objectives presented above underpin my research vision and
scientific programme. This section now present how I intend to \emph{implement}
these objectives, i.e.  what are the major research directions that I will
research, develop and establish as active research fields in the coming years.

\vspace{0.5em}
I intend to organise my research along \textbf{4+1 main research
\emph{strands}}:

\vspace{0.5em}
\begin{itemize}
    \item {\bf Strand 1} focuses on advancing the \textbf{perception of complex social
        situations}, including modeling the complexity of humans and human group
        dynamics;
    \item {\bf Strand 2} investigates the \textbf{intelligent generation of social
        behaviours}, exploring novel techniques mixing immersive teleoperation
        and adversarial generative networks;
    \item {\bf Strand 3} aims at significantly progressing the state-of-art in
        \textbf{cognitive architectures} for robots, also accounting for and integrating
        end-users in the generation of cognitive behaviours.
    \item {\bf Strand 4} focuses on framing and practically advancing what
        responsible and safe AI means in the context of social robots.
        Critically, I propose a methodology enabling the co-construction of
        these guidelines with both the general public and ethics expert. This
        work will pave the way for an international framework and concrete
        guidelines for \textbf{responsible
        human-robot interactions}.
\end{itemize}
\vspace{0.5em}


Those four research strands are all underpinned by one additional research
activity, the transversal {\bf Strand 5}. As a research scientist, I will
build-up an ambitious \textbf{experimental capacity} at LAAS-CNRS, that will
significantly improve upon the current, mostly lab-based, experimental work
conducted to date. Building on my extensive experience in real-world deployments
of autonomous social robots (see section~\ref{cv}), I will establish an
ambitious experimental programme, in close partnership with local institutions
(see section~\ref{collaborations}), based on the field's best practices that I
have contributed to establish~\parencite{baxter2016characterising}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Overview and coherence of the research programme}

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{wps}
\caption{Overview of the research strands that I intend to develop as a CNRS
    research scientist.}
\label{fig:wps}
\end{figure}

These five strands are tightly coupled, and together will enable a major
scientific and technical breakthrough in autonomous, socially-intelligent,
robots.

Figure~\ref{fig:wps} gives an overview of how the research directions interact
with each other. Fieldwork (\textbf{Strand 5}) plays a central role in my research programme, and
appears in the centre of the figure. Indeed, the deployment of autonomous social
robots in real-world, meaningful social spaces (eg. in schools, Toulouse's
Purpan hospital, Toulouse's science centre 'Le Quai des Savoirs', etc) will be
integral to my research methodology, and will enable the development of
`public-in-the-loop' experiments (4.2): the public, by co-designing interventions,
interacting and, at time, taking direct control of the robots, will shape what a
useful and socially acceptable interaction looks like, and lead to the
\emph{definition of core interaction principles}. Using machine learning to learn from
these field experiments (3.2), these core principles are in turn translated into
algorithmic models, guiding the \emph{social teleology} of the cognitive architecture
(3.1).

The regular fieldwork I intend to conduct will also provide the source of data
to feed into to Strand 1: \textbf{Strand 1}, focusing on \emph{social situation
assessment}, researches, develops, and integrates all the components pertaining
to the assessment of the spatio-temporal and social environment of the robot.
Reference interaction situations and the interaction datasets required to
support this research is directly drawn from the experimental fieldwork, as well
as an additional, focused experimental programme on mental states modeling that
I detail in the following sections.

These perceptual capabilities are both (1) continuously integrated into the
robot's cognitive architecture (3.3), iteratively improving the socio-cognitive
performances of the robot, (2) disseminated to the broader community through
standardisation and integration to the ROS ecosystem.

\textbf{Strand 2} looks into behaviour generation using immersive teleoperation
to investigate novel non-verbal interaction modalities (2.1), combined with
new developments in machine learning to learn and automatically generate them
(2.2). In this research strand, I will focus on researching new way of
automatically generating rich behaviours (including eg expressive gestures,
expressive motions) that are non-repetitive and socially congruent. I intend to
apply state-of-the-art deep generative networks to achieve this; as such, the
research strand is data-intensive, and will use datasets acquired during the
field deployments, as well as lab-recorded dataset of social interactions, using
novel immersive techniques presented below. Similar to Strand 1, the newly
developed capability of generating socially congruent behaviours is continuously
integrated in the robot architecture.


My research project includes an ambitious, beyond-state-of-art, technical work
programme, and \textbf{Strand 3} investigates the \emph{principled} integration
of a cognitive architecture for autonomous social robots.  Indeed, in addition
to the integration of the results of Strand 1 and Strand 2, Strand 3 is also
researching and developing the socio-cognitive principles, or \emph{drives} of
the architecture. They will be identified both from the 'public-in-the-loop'
research and end-user engagement conducted in \textbf{Strand 4}, and an novel
research on intrinsic social motivation that I detail below.

\subsubsection{Towards building a principled cognitive architecture}

As such, an important part of my research programme contributes to the design
and implementation of a novel, complete cognitive architecture for socially
intelligent robots. While I detail in a following section the scientific
underpinnings of this research, Figure~\ref{fig:archi} illustrates how my
different research strands combine towards that goal.

\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{figs/archi}
\caption{Contributions of my research strands to the AI architecture at the core
    of the research programme. Some capabilities already developed at the host
    lab (grey blocks) will directly contribute to the practical realisation of autonomy.}
\label{fig:archi}
\end{figure}


Strand 1 (top) focuses on creating a novel, integrated model of the social
environment of the robot; it will build on the current state of art in spatial
modeling, semantic modeling and interaction history representation, and augment
it with representations of the social dynamics around the robot, introducing the
idea of \emph{social embeddings}. Strand 2 (bottom) significantly improve upon
techniques for non-repetitive, socially-congruent behaviour production,
combining behaviour design and data acquisition using immersive teleoperation
with recent advances in generative neural nets. Strand 3 (centre) integrates the
robot cognitive capabilities in a new cognitive architecture for long-term
social autonomy. It introduces a novel arbitration mechanism between action
policies, to enable both long-term, goal-driven autonomous behaviours, and
direct in-situ learning from the robot's end-users, to ensure transparency and
human oversight.


The following sections describe in greater detail each of these research
strands, in the context of the current state-of-the-art.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Strand 1: \textbf{\wpTwo}}

My first research direction will look into integrating a full representation
system for the social environment of the robot. It builds on existing state of
art in \emph{situation assessment} and \emph{knowledge representation}, and
extend it to the social sphere.  I plan to organise my work along the following
five initial directions:

\subsubsection{1.1 -- Hybrid situation assessment and knowledge representation}

Knowledge representation and grounding is a fundamental building block for
cognitive architectures\parencite{lemaignan2017artificial,beetz2010cram}. This task
builds on existing work on symbolic knowledge representation
(eg.~\parencite{tenorth2009knowrob} or my own work~\parencite{lemaignan2010oro}) and my
work on situation assessment~\parencite{lemaignan2018underworlds} (that includes for
instance object recognition and physics
simulation~\parencite{sallami2019simulation}), to create a coherent system of
representations for the cognitive architecture that extends the \sc{underworlds}
spatio-temporal representation tool~\parencite{lemaignan2018underworlds} with with
recent advances in symbolic (eg. data-driven semantic labelling, like the 4D
convolution network MinkowskiNet~\parencite{choy20194d}) and hybrid (like
\emph{conceptors}~\parencite{jaeger2014controlling}) representations capabilities.

\begin{framed}
    {\noindent\bf Main outcomes of 1.1:} an extensible multi-modal
    software platform, that robustly tracks and represents the spatio-temporal
    environment of the robot (including the locations and objects in the robot
    vicinity).
\end{framed}

\subsubsection{1.2 -- Multi-modal human model}

This workpackage focuses on the acquisition, processing and modelling of social
signals~\parencite{gunes2017automatic} to build a multi-modal model of the humans
in the robot's vicinity. I have recently introduced a dataset of social
interaction~\parencite{lemaignan2018pinsoro} that enables for the first time a
quantitative, data-driven investigation of social dynamics. Promising initial
results led me to uncover three latent constructs that underpin social
interactions~\parencite{bartlett2019what}. This dataset and the related methodologies
on data-driven social modeling will form the basis of this research workpackage,
and will exploit the natural interaction data collected in Strand 5.

\begin{framed}
    {\noindent\bf Main outcome of 1.2:} A data-driven social signal processing
    pipeline to model the surrounding humans.
\end{framed}

\subsubsection{1.3 -- Interaction and group dynamics}

Building on 1.2, 1.3
investigates the automatic understanding and modelling of group-level social
interactions~\parencite{tapus2019perceiving}, including
$f$-formations~\parencite{marshall2011using}, sociograms (as done
in~\parencite{garcia2016hybrid} for instance), and inter-personal
affordances~\parencite{pandey2013affordance}. This task builds on literature on on
social dynamics analysis (eg~\parencite{durantin2017social,jermann2009physical,
martinez2019collocated}) to apply it to real-time social assessment by a robot,
itself embedded into the interaction.

\begin{framed}
    {\noindent\bf Main outcome of 1.3:} the software pipeline required for the automatic analysis of social
    dynamics at group-level, able to model in real-time the social context
    of the robot.
\end{framed}


\subsubsection{1.4 -- Social situation assessment}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{pipeline}
    \caption{Overview of the 'ROS4HRI' pipeline that I currently develop.}
    \label{fig:ros4hri}
\end{figure}

In 1.4, I integrate the social
cues from 1.2 and 1.3 into the representation platform developed in 1.1. It will
result in a socio-cognitive model of the social environment of the robot that I
term \emph{social situation assessment}. It effectively extends the
representation capabilities of implemented in 1.1 to the social sphere, and covers the
development of a complete social assessment pipeline, from social signal
perception (like automatic attention tracking, face recognition, sound
localisation, etc.) to higher-level socio-cognitive constructs, including group
dynamics and perspective taking~\parencite{flavell1992perspectives} (as I previously
framed in~\parencite{lemaignan2015mutual, dillenbourg2016symmetry}).

\begin{framed}
    {\noindent\bf Main outcome of 1.4:} a novel cognitive sub-system for social
    situation assessment, released as an open-source set of integrated ROS
    modules ("\emph{ROS4HRI}", Figure~\ref{fig:ros4hri}). This set of tools will enable the robot to
    represent its physical and social environment, and perform queries about it,
    including queries about past events (temporal model) and queries requiring
    higher socio-cognitive perceptual capabilities like perspective taking.
\end{framed}


\subsubsection{1.5 -- Social embeddings}

One of the key novel scientific idea that I will research in this workpackage is
the construction of the \textbf{social embedding} of the robot:
a compact, low-dimensional representation of the full social environment,
inspired from word embeddings (eg.~\parencite{mikolov2013distributed}). If fruitful,
this approach would significantly simplify the application of neural networks to
automatically recognise social situations and social dynamics (something notoriously difficult
to achieve with the current state-of-art~\parencite{bartlett2019what}), and
potentially \emph{generate} plausible social situations, that the robot could
use to eg. predict the next states of an interaction.

\begin{framed}
    {\noindent\bf Main outcome of 1.5:} the investigation of \emph{social
    embeddings} as a general, sub-symbolic representation of the social
    environment of interactive robots.
\end{framed}

\subsubsection{Experimental programme of Strand 1}

In complement to the large-scale experimental work described in Strand 5, a focused experimental programme accompanies Strand 1, to demonstrate (in relative
isolation) the resulting socio-cognitive capabilities. I will implement a subset
of the experimental protocols identified by Frith and
Happ√©~\parencite{frith1994autism} to investigate theory of mind with autistic
children, as it offers an excellent experimental framework for social
robotics, as I argued in~\parencite{lemaignan2015mutual}.

Indeed, experimental protocols in research on autistic spectrum disorders are often
striking by their apparent straightforwardness because of the careful choice of
interaction modalities: since autistic children frequently exhibit impairments
beyond social ones (such as motor or linguistic ones), the experiments must be
designed such that they require only basic cognitive skills beyond the social
abilities that are tested. The Sally and Anne task, for instance, requires the
observing child to be able to visually follow the marble, to remember the true
location of the marble, to understand simple questions (``Where will Sally look
for her marble?'' in Baron-Cohen's protocol~\parencite{baron1985does}) and eventually
to give an answer, either verbally or with a gesture -- the two first points
being actually explicitly checked through questions: ``Where is the marble
really?'' (reality control question) and ``Where was the marble in the
beginning?'' (memory control question).

Likewise, current social robots have limited cognitive skills (no fast yet fine
motor skills, limited speech production and understanding, limited scene
segmentation and object recognition capabilities, etc.) and such tasks that
effectively test a single cognitive skill (in this case, mentalizing) in near
isolation are of high relevance for experimental social
robotics~\parencite{lemaignan2015mutual}, offering rich experimental
opportunities, early on in the development process of the complete cognitive
architecture.

\begin{table}[h]
    \centering
    \begin{tabular}{p{0.4\linewidth}p{0.5\linewidth}}
        \toprule
        No mentalizing required           & Mentalizing required          \\
        \midrule
        Ordering behavioural pictures     & Ordering mentalistic pictures\parencite{baron1986mechanical} \\
        Understanding see                 & Understanding know\parencite{perner1989exploration}            \\
        Protoimperative pointing          & Protodeclarative pointing\parencite{baron1989perceptual}     \\
        Sabotage                          & Deception\parencite{sodian1992deception}                     \\
        False photographs                 & False beliefs\parencite{leslie1992domain}                 \\
        Recognizing happiness and sadness & Recognizing surprise\parencite{baron1993children}          \\
        Object occlusion                  & Information occlusion\parencite{baron1992out}         \\
        Literal expression                & Metaphorical expression\parencite{happe1993communicative}       \\
        \bottomrule
    \end{tabular}
    \caption{\small Tasks requiring or not mentalizing to pass, listed by Frith and Happ√© in\parencite{frith1994autism}}
    \label{mentalizing-tasks}
\end{table}

Frith and Happ√©'s list (Table~\ref{mentalizing-tasks}) is in that regard
especially interesting in that it mirrors pairs of task (ones which do not
require mentalizing with similar ones which do require mentalizing), thus
providing control tasks. \emph{Object occlusion} vs.~\emph{Information
occlusion} is one example of a pair of tasks which evidence
representation-level perspective taking through \emph{adaptive deception}.
%during a simple game, the experimenter adapts its strategy
%(deceptive/non-deceptive behaviour) to the representation skills of its child
%opponent. The experimental setting is derived from the penny-hiding game
%protocol originally proposed by Oswald and Ollendick\parencite{oswald1989role} and
%replicated and extended by Baron-Cohen in\parencite{baron1992out}, who describes it
%as a two-person game in which the subject is actively involved, either as a
%guesser or as a hider. The hider hides the penny in one hand or the other, and
%then invites a guess. The game is repeated several time before switching the
%roles. Baron-Cohen proposes a specific index to rate the level of the players
%based on the idea of \emph{information occlusion}: minimally, the hider must
%ensure \emph{object occlusion} (the penny must not become visible to the
%guesser), while good hiders, with representation-level perspective taking
%skills, develop strategies (like random hand switching or deictic hints at the
%wrong hand) to prevent the guesser to find the penny (\emph{information
%occlusion}).
Adapting such a protocol for a human-robot pair would demonstrate
\emph{second-order}, \emph{representation-level} perspective
taking capabilities, which is beyond the state-of-the-art in an artificial
cognitive system.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Strand 2: \textbf{\wpThree}} 


Mirroring Strand 1's focus on understanding the social interactions, Strand 2
addresses the question of social behaviour \emph{generation}: how to create
natural behaviours, engaging over a sustained period of time (eg not simply
picking scripted behaviours from a library, that are rapidly perceived as
repetitive).

The focus of my research will be in the first instance on \emph{non-verbal}
behaviours (however, see Section~\ref{collaborations} for planned collaborations
on \emph{verbal} behaviours). This is a purposeful interaction design choice,
that ensures we can more effectively manage what cognitive capabilities are
ascribed to the robot by the users (expectation management).  I seek however to
significantly push forward the state-of-the-art of behaviour generation for
robots, both in term of technique to generate the behaviours, and in term of the
nature of the non-verbal behaviours (including expressive gestures and motion,
non-verbal utterances using sounds, gaze, joint attention).

This strand of research will build upon the long expertise of the LAAS-CNRS on
developing social robots interacting with humans in complex
environments~\cite{Lallement2014,gharbi2013natural,
waldhart2015planning}\TODO{add additional/better references}, as well as the
existing literature on current behaviour generation methodologies, covering
techniques like curiosity-driven behaviours\parencite{oudeyer2005playground},
Learning from Demonstration\parencite{billard2008robot, argall2009survey},
human-in-the-loop action policy learning\parencite{senft2016sparc,
senft2019teaching}.



\subsubsection{2.1: Immersive teleoperation to design richer non-verbal
interactions}

%\begin{figure}[!htbp]
%\centering
%    \includegraphics[width=0.7\textwidth]{figs/cozmo-expression-sheet.jpg}
%\caption{Cozmo facial expressions}
%\end{figure}

As part of Strand 2, I also intend to lead research on novel non-verbal
interaction modality for social robots. This direction of research, tightly
related to the previous one, will pursue an interdisciplinary approach: from
creating a novel body language for social robot with choreographers, to
investigating new forms of sound expressions like soundscapes with sound
experts: soundscapes are about creating a sound environment that reflects a
particular situation; they also have been shown to be an effective intervention
technique in the context special needs treatments
(eg~\parencite{greher2010soundscape}). The soundscapes that we will research and
create, are `owned' by the robot, and it can manipulate it itself, eg to create
an approachable, non-threatening, non-judgmental, social interaction context, or
to the establish the interaction into a trusted physical and emotional
safe-space for the children.

\TODO{Complete the 'immersive teleoperation for behaviour design' part}

 with a dataset co-created with artists (for instance,
a choreographer): during a period of time, a choreographer would join the lab and remotely `puppet'
a robot which would be itself interacting with the lab members
(Figure~\ref{fig:puppet-robot})

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{figs/puppet.pdf}
    \caption{\label{fig:puppet-robot} (left) Possible appearance of a
    puppet-robot that I will use to collect data. A tablet, displaying facial
    animations, is mounted on a robotic arm.  It can freely orient its `gaze'
    and use expressive movements. The robot is effectively teleoperated in
    realtime by an artist (eg choreographer, right) who 'sees through the
    robots' eyes'~\parencite{bailly2015beaming} and who is tasked with designing and
    acting a novel 'body language' for social interactions.}

\end{figure}


\begin{framed}
    {\noindent\bf Main outcomes of 2.1:} the research, development and
    implementation of novel non-verbal communication modalities, including for
    instance a robot 'body language' for social interactions and soundscapes; a
    large dataset of such interactions, recorded in immersive conditions, and
    suitable for machine learning.

\end{framed}


\subsection{2.1 -- Generative neural network for social behaviour production}

%Designing behaviours that
%enable sustained, long-term engagement in a social human-robot interaction is
%essentially an open research question. Three main approaches to social
%behaviours generation exist today: \emph{user-induced}, where the end-user
%interacts with the robot and ascribes (knowingly or not) complex behaviours to
%the machine, while in reality the robot's behaviours are simple and non-goal
%oriented (eg generating a noise or a small movement when being touched). This
%has been used to great effect in therapy robots, for instance (eg Paro).
%\emph{Off-the-shelf behaviours}, where the robot relies on a set library of
%behaviours (that might be individually relatively complex). The approach can
%elicit a strong initial social response from the user, but this social response
%tends to vanish rapidly once the `tricks' of the robot have been all discovered
%and become repetitive.  Besides, as the robot does not typically maintain a
%long-term socio-cognitive plan of the interaction, the behaviours are typically
%perceived as fun, yet pointless. This is often observed in toy-like robots (eg
%Vector, Dot \& Dash). Finally, many social robots avoid altogether the problem
%of generating behaviours by simply offering to the end-user control over
%\emph{low-level behaviours} (eg, control of the joints of the robot). This means
%that, even when the robot has relatively powerful social perception capabilities
%(like recognising people and voice), no real social behaviours is generated.
%
%None of these three approaches are satisfactory, and indeed, no approach to date
%has been able to engage human users in long-term, sustained
%interactions~\parencite{hoffman2019anki}.

Designing behaviours that enable sustained, long-term engagement in a social
human-robot interaction is essentially an open research question. The specific
challenge of producing non-repetitive social behaviours is particularly
difficult: social robots typically rely on \emph{off-the-shelf behaviours},
where the robot effectively picks from a set library of behaviours (that might
be individually relatively complex). The approach can elicit a strong initial
social response from the user, but this social response tends to vanish rapidly
once the `tricks' of the robot have been all discovered and become repetitive.
Besides, as the robot does not typically maintain a long-term socio-cognitive
plan of the interaction, the behaviours are typically perceived as fun, yet
pointless, leading to disengagement. This is often observed in toy-like robots
(eg Vector, Dot \& Dash)~\parencite{hoffman2019anki}.

The LAAS-CNRS has played a pioneering role in this field with eg the development
of HATP as a hybrid task-planner for human-robot
interaction~\cite{Alili2008,Lallement2014} or human-aware motion
planning~\cite{gharbi2013natural, waldhart2015planning}. While effectively
enabling the robot to store and manage long-term plans, symbolic task planners
still rely on mostly static libraries of 'canned', repetitive actions. Also
neither of these planners are well-suited to rapid, dynamic behaviours
generation, especially in situations requiring performing parallel, blended
actions.

Building on these solid foundations, I aim at significantly advancing the state
of the art in this regard, by combining two recent machine-learning techniques:
(1) generative neural networks for affective robot motion
generation~\parencite{yang2019appgan,marmpena2019generating,suguitan2020moveae};
(2) interactive machine learning in high-dimensional input/output spaces, where
I have shown with my students promising results for generating complex social
behaviours~\parencite{senft2019teaching, winkle2020insitu} that fully involve
the end-users~\parencite{winkle2018social}.

In~\parencite{suguitan2020moveae}, a Generative Adversarial Network (GAN) is
trained to generate expressive motions; the generation being modulated by a
feature encoding an emotion. I will extend this idea in two ways: (1) I will
train the GAN on multiple interaction modalities (motions, but also facial
expressions, gaze, sounds) using the data acquired in 2.1. The aim will be to collect a
large amount of data to train a GAN from, effectively creating a new
multi-modal `grammar' for the robot expression.  (2) Instead of using emotions
to modulate the generation stage, I will use the social embedding constructed in
1.5: the generated behaviours will be shaped by the current, complex social
state of the interaction instead of simply emotions.
%
%
%
%At a time where companion robots are coming to the market, one important
%question remains fully open: how to design robot behaviours that foster
%lasting engagement? A vast body of academic literature identifies that
%robots evoke an initial phase of high user engagement (the
%\emph{novelty} phase) that vanishes as the user realises that the robot
%is actually quite predictable and repetitive. The \emph{agency}
%initially ascribed by the user to the robot quickly
%fades\parencite{lemaignan2014dynamics}, leading to critical user disengagement from the technology.
%
%
%The (often limited) library of behaviours available to the robot is
%often cited as a key factor in causing this issue. However, another,
%more profound issue affecting long term engagement with robot companions
%is the question of \emph{purpose.} Without clear \emph{purpose}, social
%robot companions can lack \emph{usefulness}. Indeed, robot
%\emph{companions} might not have explicit goals that would dictate or
%motivate their behaviours: they aim at providing a social presence, a
%social comfort, as cats or dogs would do, without necessarily being
%goal-oriented.
%
%Recent attempts -- and failures -- to convert social robotics research
%into commercial platforms (Jibo, Kuri and most recently Anki's Cozmo and
%Vector robots) reflect exactly this, with reasons for their failure
%typically citing an under-delivery of the user experience they promised,
%and/or the lack of a `real need' to justify their price point. The
%\project project addresses these two key issues by:
%
%\begin{enumerate}
%\def\labelenumi{\arabic{enumi}.}
%\item
%  Taking inspiration from human-pet relationships which also have no
%  explicit \emph{purpose} beyond their potential for enjoyable,
%  \emph{affective} interactions;
%\item
%  Working with creative professionals who excel at storytelling and
%  emotional engagement to overcome the problems in sustaining
%        engagement, as proposed by Hoffman\parencite{hoffman2019anki}
%\item
%  Blending these two sources of inspiration using a radically novel
%  combination of immersive teleoperation and machine learning.
%\end{enumerate}
%
%The project is \emph{not} about replicating a pet's behaviour per se. It
%is instead about identifying, modeling and automatically generating the
%social behaviours required to recreate pet-like social dynamics between
%robots and humans, drawing inspiration from ethology (Stanton, Sullivan,
%and Fazio 2015). Using animal behaviours to inform the design of robots
%is not new, the most remarkable example being the Sony AIBO robot dog,
%whose behaviours were directly designed around those of actual dogs
%(Arkin et al. 2003). However, to go beyond the repetitive interactions
%associated with such robots, we propose to employ a creative
%professional to actively participate in design and automation of \project
%behaviour. The concept of using creative professionals to `teach' social
%robot behaviour is not new either (Knight and Gray 2012), however it is
%only recent advances in human-in-the-loop, online machine learning that
%make this type of real-time `social training' a feasible approach to
%generating and automating engaging social behaviours (Senft et al.
%2019).
%
%Our project has the following goals, addressed by the workplan presented
%below:
%
%\begin{enumerate}
%\def\labelenumi{\arabic{enumi}.}
%\item
%  assemble a non-anthropomorphic social robot that can autonomously
%  navigate in a complex and living lab environment, taking inspiration
%  from ethology to inspire the robot's behaviour;
%\item
%  develop an immersive teleoperation system, enabling a creative
%  professional to `take control' of the robot (i.e.~puppet the robot) in
%  a completely intuitive way (using whole body motion tracking);
%\item
%  record (and make publicly available) a large dataset of social
%  behaviours (created through immersive teleoperation) that foster
%  long-term social and affective engagement. The dataset will also
%  include the social \emph{signals} implicitly used by the puppeteer to
%  drive his/her choice of actions (recorded through eg eye-tracking);
%\item
%  using machine learning, map these social signals (input state) to the
%  robot behaviours (output state) such that the robot can operate
%  autonomously.
%\end{enumerate}
%
%A creative professional (puppeteer, dancer or comedian --
%corresponding financial compensation is budgeted) will join the group.
%First she/he will take part to a one-week co-design workshop (4) aiming
%at finalising the immersive teleoperation controller and the behaviours
%of the robot. Then, she/he will interact for about 4 hours a day during
%a month, with the BRL lab members (200+ researchers). She/he will do so
%by remotely operating the robot (5) from an (out-of-sight) control room
%(the BRL CAVE room). The aim will be for the puppeteer to pro-actively
%engage with people in the lab, attempting to engage in \emph{social,
%affective} interactions. This will be achieved by creating/inventing
%in-situ a new `grammar' of social behaviour, loosely inspired by those
%of cats and other pets. These interactions will be fully recorded
%(including eye-tracking on the puppeeter) (6), in order to create a
%unique dataset of complex social interactions, suitable for machine
%learning. The PI has already extensive experience in recording such
%datasets (see (Lemaignan et al. 2018) for instance).
%
%%%\begin{wrapfigure}[17]{l}{8cm}
%%\begin{figure}
%%    \centering
%%    \includegraphics[width=0.8\paperwidth]{figs/dev.pdf}
%%    \caption{\label{fig:support}
%%    Social behaviours will be learned from immersive `puppetering' of the
%%    robot, performed by a professional actor. The `puppetering' takes place
%%    in a CAVE (or VR) environment, where what the robot `sees' and `hears'
%%    is streamed live}
%%\end{figure}
%%%\end{wrapfigure}
%
%Over the following four months, a deep neural network will be designed
%and trained (7) for the regression task of generating continuous social
%behaviours from perceived social signals. In parallel, a software
%controller will be developed (8) to enable generic autonomous
%capabilities (like autonomous navigation) for which the BRL has
%extensive expertise.
%
%Finally, the last four months will be dedicated to in-situ testing of
%the autonomous system (9). We will seek to conduct a large scale study
%within the lab, over a period of several weeks. For this study, the
%robot is expected to be fully autonomous. However sufficient amount of
%time is planned for additional iterations on the development of the
%robot controller if deemed necessary. We aim at publishing the results
%of this main study shortly after the end of the one-year period.

\begin{framed}
    {\noindent\bf Main outcomes of 2.2:} a generative neural network
    able to produce non-verbal yet multi-modal social behaviours. They will
    combine expressive gestures, gazing behaviours, facial expressions, and
    expressive sounds.
\end{framed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Strand 3: \textbf{\wpFour}}

Strand 3 investigates the principled integration of a cognitive
architecture for autonomous social robots. It binds together the socio-cognitive
perceptual capabilities of the robot developed in the Strand 1, the action
production mechanisms developed in the Strand 2, and includes key elements from
my 'human-in-the-loop' methodology to isolate and model the interaction principles
and social goals of the robot.

\subsubsection{3.1 -- A social teleology for robots}

\emph{Teleological systems} (ie goal-driven) have been investigated in robotics
for being a way of providing long-term drives to an autonomous robot. This has
been successfully applied to relatively simple cognitive
systems~\parencite{oudeyer2005playground,moulinfrier2014self} or virtual
agents~\parencite{pathak2017curiosity}. This first basic research activity in
Strand 3 aims to significantly progress this line of research, and to look into
\emph{complex} interactive cognitive systems. The key objective of this work
package 3.1 is to define and implement a novel \emph{social teleology}: the
\textbf{algorithmic encoding of long-term social goals} into the robot.

This work will directly draw from the participatory, 'human-in-the-loop'
methodological paradigms that present in Strand 5. Indeed, before being
transposed into algorithms, these long-term social goals will first be
co-defined and co-created by the end-users and the public in terms of
\emph{interaction principles for useful and responsible social robots}.

\begin{framed}
    {\noindent\bf Main outcomes of 3.1:} the algorithmic translation of 
    interaction principles into long-term social goals for the robot; eg a
    long-term, socially-driven action policy for the robot.
\end{framed}

\textbf{3.2 -- Learning from humans to achieve `by-design' responsible \&
trustworthy AI}

I have recently obtained promising results on human-in-the-loop social
learning~\parencite{senft2019teaching,winkle2020insitu}: non-expert end-users
teach in-situ (eg at school, at the gym, etc.) a robot, which progressively
learns to be autonomous, eventually reaching full task- and social autonomy.
This approach, that I developed with one of my
students~\parencite{senft2017supervised}, holds a lot of promise in term of
field acceptance of social robots as it entrust the end-user with a high level
of control during the learning phase, leading to a feeling of ownership of the
resulting robot behaviours.  I will further develop this idea, applying in-situ
interactive reinforcement learning to more complex, real-world, situations.

In addition, I will study through qualitative methods (thematic interviews and
questionnaires) whether (and how) human-in-the-loop machine learning enables a
more trustworthy AI system, by involving the end-users in the creation of the
robot behaviours, thus offering a level of behavioural transparency to the
end-users.

\begin{framed}
    {\noindent\bf Main outcomes of 3.2:} a human-in-the-loop reinforcement
    learning paradigm, suitable for in-situ teaching of the robot by the
    end-users themselves, demonstrated in complex social environments.
\end{framed}

\textbf{3.3 -- Integrating a socially-driven architecture for long-term interaction}

This research strand builds on the state of art in cognitive architectures
(disembodied
ones~\parencite{chong2007integrated,vernon2007survey,kingdon2008review,duch2008cognitive,langley2009cognitive,taatgen2010past,thorisson2012cognitive},
as well as ones specifically developed for robotics:
ACT-R/E~\parencite{trafton2013act}, HAMMER~\parencite{demiris2006hierarchical},
PEIS Ecology~\parencite{saffiotti2005peis,daoutis2012cooperative},
CRAM/KnowRob~\parencite{beetz2010cram, tenorth2009knowrob},
KeJia~\parencite{chen2010developing}, POETICON++~\parencite{antunes2016from}, and
the LAAS Architecture for Social
Interaction~\parencite{lemaignan2017artificial}, to which I have been a key
contributor during my PhD). The overall purpose of this
socio-cognitive architecture is to integrate in a principled way the
spatio-temporal and social knowledge of the robot (Strand 1) with a decision-making
mechanism, to eventually produce socially-suitable actions (Strand 3). 

The decision-making mechanism is critical, and lay at the heart of my research
project. The robot will rely on it to generate action decision that are
purposeful, legible and engaging on the long run, something that none of the
existing architectures have been able to successfully demonstrate to date. I aim
at a breakthrough, and will introduce a novel approach: drawing from the
interaction patterns identified (Strand 4), I will combine long-term,
socially-driven goals (the \emph{social teleology}, 3.1), and human-in-the-loop
machine learning (3.2) using a novel arbitration mechanism.

The arbitration mechanism itself will build on research on reinforcement
learning for experience transfer~\parencite{madden2004transfer} that enables the
re-assessement of a policy (here, our long-term social teleology) based on
specific experience (here, the end-user-taught policy).


\begin{framed}
    {\noindent\bf Main outcomes of 3.3:} A cognitive architecture, implemented
    on the LAAS social robots, that enables long-term social engagement, by combining
    long-term goals with domain-specific action policies, taught by the
    end-users themselves.
\end{framed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Strand 4: \textbf{\wpOne}}

The basic, long-term ambition of my research programme is to re-investigate the
underpinnings of human-robot interaction by taking a \textbf{strong
human-centered perspective}. I frame this as a shift from \emph{human-robot
interaction} to \emph{robot-supported human-human interactions} (r-HHI). This
last major strand of research operationalises this objective as two main tasks:
a theoretical contribution, examining the interplay between r-HHI, responsible
AI, and ethics; and a large-scale study to gather public input.

\subsubsection{4.1 -- Conceptual framing of r-HHI and ethical framework} 

The first task in Strand 4 is to research and define the framework that will provide
the conceptual frame around questions like: what role should social robots have?
Where to set the boundaries of artificial social interactions? What does
`ethical-by-design', `responsible-by-design' mean in the context of social
human-robot interactions?

Indeed, my research project involves social robots, interacting in repeated ways and
over long period of time, with human end-users, including vulnerable children.
This raises complex ethical issues, both practical ones (how to design the
experimental work in a such a way that they are safe and ethically sound), and
more fundamental ones (what is the ethical framework for robots intervening in
socially sensitive environment?).

The ethical questions raised by social robotics have been actively studied over
the last 5 years, attempting to address issues like:

\begin{itemize}
    \item how to ensure that social robots are not used to simply replace the human
        workforce to cut costs?
    \item can we provide guarantees that the use of social robots will always be
        ethically motivated?
    \item further on, can we implement some ethical safeguarding built-in
        the system (like an ethical \emph{black-box}~\parencite{winfield2017case})?
    \item what about privacy? how to trust robots in our home or school or
        hospital not to eavesdrop on our private lives, and, in the worst
        case, not be used \emph{against} us?
\end{itemize}

These questions are indeed pressing. The recent rise of personal assistants like
Amazon Alexa or Google Home, with the major privacy concerns that accompanies
their deployments in people home, shows that letting the industry set the agenda
on these questions is not entirely wise -- and robots can potentially be much
more intrusive than non-mobile smart speakers.  The EU is positioning itself at
the forefront of those questions. The recent release of operational \textbf{Ethics
Guidelines for Trustworthy AI} by the EU High-level Expert Group on Artificial
Intelligence~\parencite{eu2019ethics} is a strong sign of this commitment. These
guidelines identify seven requirements of trustworthy AI:

\begin{enumerate}[label=\textbf{R\arabic*}]
    \item \textbf{Human agency and oversight}, including
            fundamental rights, human agency and human oversight

    \item \textbf{Technical robustness and safety}, including resilience to
        attack and security, fall back plan and general safety, accuracy,
        reliability and reproducibility

    \item \textbf{Privacy and data governance}, including respect for privacy,
        quality and integrity of data, and access to data

    \item \textbf{Transparency}, including traceability, explainability and
        communication

    \item \textbf{Diversity, non-discrimination and fairness}, including the
        avoidance of unfair bias, accessibility and universal design, and
        stakeholder participation

    \item \textbf{Societal and environmental wellbeing}, including
        sustainability and environmental friendliness, social impact, society
        and democracy

    \item \textbf{Accountability}, including auditability, minimisation and
        reporting of negative impact, trade-offs and redress.

\end{enumerate}

The design methodologies and techniques employed in my research programme naturally implement
most of these requirements: interaction co-design and human-in-the-loop machine
learning ensures human agency oversight over the robot's behaviours (R1);
Privacy and data governance (R3) is addressed in the project's data management
plan and facilitated by the design decision of performing all data processing
on-board the robot, avoiding the dissemination of personal information; the
transparency of the robot behaviour (R4) stems from the machine learning
approach that we advocate: the robot's behaviours primarily originate from what
the end-users themselves taught the robot; diversity and non-discrimination (R5)
is supported by the large-scale involvement of the public at the science centre,
ensuring a broad diversity of backgrounds and profiles; societal wellbeing (R6)
is the core research question of the project, and I intend to contribute in
realising this requirement in the context of social robots.

Technical robustness (R2) and accountability (R7) are important design
guidelines for the robot's cognitive architecture (WP4), and will be addressed
there as well.


The Ethics Guidelines for Trustworthy AI form a solid foundation for the
project. However, personal and social robots raise additional questions
regarding what ethical and trustworthy systems might look like, and while the
principles of responsible design are somewhat established~\parencite{stahl2016ethics,
bsi2016robots}, the reality of robot-influenced social interactions is not
fully understood yet, if only because the technology required to experience such
interactions is only slowly maturing. 

Social robots have indeed two properties that stand out, and distinguish them
from smart speakers, for instance.  First, they are fully embodied, and they
physically interact with their environment, from moving around, to picking up
objects, to looking at you; second, willingly or not, they are ascribed
\emph{agency} by people. This second difference has far-reaching consequences,
from affective bonding to over-trust, to over-disclosure of personal, possibly
sensitive, informations~\parencite{martelaro2016tell,shiomi2017robot}.  As an
example, a common objection to human-robot interaction is the perceived
deceptive nature of the robot's role. It has been
argued~\parencite{biscontilucidi2018companion} that the underlying concern is likely
the lack of an adequate (and novel) model of human-robot interactions to refer
to, to which the project will provide elements of response. This needs
nevertheless to be accounted for in depth.

Ethical framing of social robotics has started to
emerge under the term \textbf{roboethics}: the ``subfield of applied ethics
studying both the positive and negative implications of robotics for individuals
and society, with a view to inspire the moral design, development and use of
so-called intelligent/autonomous robots, and help prevent their misuse against
humankind.''~\parencite{allen2011robot}. Specific subfields, like assistive
robotics~\parencite{sharkey2012granny}, have seen some additional work, but social
robotics is still not equipped with operational guidelines, similar to the EU
guidelines on trustworthy AI.

This is my ambition that my research will significantly contribute to the
framing and the building of guidelines and recommendations for responsible
human-robot interactions, enabling a safe and trustworthy  digital future in our
society.

I intend to develop this line of research by adopting the same open-science
approach, involving the general public in the process: my field work
experiments (Strand 5) will both \emph{build on} and
\emph{feed into} the framework developed in this research strand.

In addition, I will also structure this framing effort through international
workshop. During these workshops, invited ethics experts (from both robotics and
AI backgrounds) will be invited to engage with field practitioners, including
local institutions where the experimental work will have taken place. These
regular forums will be coordinated with the European Commission (I am already
acting as an Expert Collaborator on ethics for the European Joint Research
Centre), and will create a public opportunity to debate and iterate over
ethics guidelines for responsible long-term social interactions with robots.

\begin{framed}
    {\noindent\bf Main outcomes of 4.1:} a conceptual framework that clarify and
    organise together the questions raised by long-term social interactions;
    initial ethical guidelines for such interactions, aimed at informing future
    policy making.
\end{framed}


\subsubsection{4.2 -- Crowd-sourced patterns of robot-supported social
interactions}

In order to broadly engage the public with defining what future robots should do
to be perceived as responsible, beneficial, and engaging, I intend to create and
deploy a novel investigation methodology that I term `experimental
crowd-sourcing'. For one year, in close partnership with local institutions
(like Toulouse's "Le Quai des Savoirs"), the general public will be invited to
teleoperate my robots, with the objective of interacting and assisting
other visitors. The participants will remotely control the robot through a
tablet interface (similar to the setup I created
for~\parencite{senft2019teaching} and~\parencite{winkle2020insitu}), and
interviews of both the teleoperators and the visitors interacting with the robot
will be conducted in parallel, collecting in a structured manner the interaction
patterns and social norms that will emerge over the course of the study.
Additional focus groups will be organised with the public to reflect and
iterate on these principles.

\TODO{finish that}
During the duration of the study, one researcher will be permanently based at
the science museum, and the museum staff themselves will be trained to
communicate about the aims of the study. Anonymous interaction data (eg, body
postures) will be collected as well, and feed into WP2 and WP3.

\begin{framed}
    {\noindent\bf Main outcomes of 4.2:} a set of crowd-sourced interaction
    patterns and principles, that will inform the long-term social goals of the
    robot (4.1); a large dataset of social interactions to feed into Strands 2
    and 3.
\end{framed}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WeTheCurious
% 
% - one robot completelty controlled by children, one by adults
% 
% what to learn?
% 
% - when to approach? when to prompt? [example of the salesman/museum facilitator]
% - when is the right time to help/intervene or not? 'child being told off by
% parents -> not the right time!'
% - group interactions -> when to intervene? what about peer-pressure? eg what if
% I tell off one child in front of another?
% - break the barrier for participation. Japanese Journal paper -> facilitating students questions
% - impact on moral norms? what behaviours is acceptable?
% - what role for the robot? another mediator? a peer?
% - what can we do with that 'alien creature'
% 
% - robot taking one child to talk to the museum mediators ("I, robot, am  shy!
% would you come with me?")
% 
% - learning how to adjust behaviour based on personality
% - 'why do I behave like that with that person, and like this with that other
% person?'
% 
% - reinforcement learning instead of human-in-the-loop -> what reinforcement
% signal? engagement
% 
% - the robot that 'take sides': take side against the adults? -> bending in its
% role?
% 
% 
% - social embarassment
% - space for pretence: the robot can adopt an 'artificial role' as long as it is
% possible (accpetable/...) to pretend the robot is



\subsection{Strand 5: \textbf{\wpFive}}

I have the ambition to demonstrate long-term, co-designed social
interactions in two complex, socially sensitive spaces.

\TODO{Revisit this section to adapt to local environment}

The first one involves the deployment of social robots in special needs schools
(SEN schools) in Bristol (T5.1). Building on a rigorous participatory approach
involving the school teachers, as well as the parents, we will seek to integrate
the robot in the daily life of the school, supporting the development of the
students' physical and social skills. The second one takes place in Bristol's
Children's Hospital (T5.2), supporting isolated children who suffer long-term
conditions, in close cooperation with the hospital staff. In both cases, a
social robot will be deployed on premises, for one un-interrupted year. It will
integrate the daily routines of the institutions, under supervised
autonomy~\parencite{senft2017supervised}, and \emph{without} requiring the
presence of a researcher at all time.

These two experiments raise specific practical and ethical questions, as they
target vulnerable populations. This is an however informed choice: first, I
already have established partnerships with Bristol's children hospital on one
hand, and a network of Bristol-based SEN schools on the other hand. As such, and
from a practical perspective, I do not foresee any institutional issues -- on
the contrary, our partners are excited at the prospect of taking part to the
project. Besides, convincingly demonstrating the importance and positive impact
of socially-driven, socially-responsible robotics does accordingly require
complex social situations, and complex social dynamics. The two scenarios, which
complement each other, provide both. These scenarios also put the project in the
unique position of actually delivering high societal impact: we anticipate 30+
hospitalised children with long-term conditions, and 250+ SEN-educated children
to directly benefit of the project, showing how robots can have a lasting,
beneficial impact on the society, alongside human carers: it will establish the
idea of \emph{robots supporting human interactions} instead of dehumanising our
social relationships.

Both these deployments will take place within the strict ethical framework
established in T1.1, the ethical considerations pertaining to these experiments
are further discussed below, in the section on ethics, and in the separate annex
on ethics, uploaded alongside this proposal.



\subsubsection{Experimental approach}

My experimental approach has two phases. First, I will co-design and
co-construct the robot's social role and behaviours through large-scale public
engagement. For a whole year, I will deploy the \project robot within the Open
City Lab of Bristol Science Centre \emph{WeTheCurious}, relinquishing its
control to the visitors themselves. Tasked with remotely operating the robot to
assist fellow visitors, a researcher will accompany them in `inventing by doing' a new
grammar of social interactions to develop answers to the questions: what does it
mean for a robot to help? How to do so in the dynamic, messy, environment of a
science centre? What are acceptable behaviours? Can we see new social norms
emerge? At the end of this experiment, we expect 1000s of people to have
experienced -- and co-designed -- how robots should interact with humans in a
positive, helpful way. Each of these experiences will contribute to
uncovering and designing the basic principles of social interaction for robots.
This work is the focus of WP1.

\begin{wrapfigure}[11]{l}{0.15\linewidth}
    \centering
    \vspace{-10pt}
    \includegraphics[width=\linewidth]{halodi-eve.jpg}
    \label{fig|EVE}
\end{wrapfigure}

While most of the interactions in the science centre will be short-lived, a
follow-on, long term (one year) experiment will take place in one of Bristol's
Special Education Needs (SEN) school where I currently run pilots, helping 250+
children with psycho-social impairments (autism) to develop their social skills
and to engage into playful social activities: telling stories, triggering group
activities with other children, providing additional social presence. Similar to
the science museum experiment, the robot behaviours will be co-designed with,
and learnt from the end-users themselves: teachers, parents, and as much as possible,
the children themselves.


Importantly, \project focuses specifically on the \ul{AI engine} of the robot: I
will use an existing robotic platform (Halodi's EVE, pictured on the left) and
develop and train the algorithms required to achieve autonomy and responsible,
long-term social utility. Indeed, after an initial training period, the robot
will be \ul{autonomous}: while the users will be provided with tools to override
the robot's decisions at any time (via both an app and touch sensors on the robot
itself), it will otherwise move and act on its own, without the need for
constant supervision.

%To this end, the robot will have ground-breaking
%perception and modelling capabilities to represent the current social situation
%(the focus of WP2), coupled with an innovative cognitive architecture designed
%to combine internal social drives with domain-specific action policies learnt
%from the end-users (WP4). The robot actions themselves are designed to be
%limited to non-verbal communication mechanisms: non-verbal utterances using
%sounds, gaze, joint attention, expressive motions. In WP3, my team will work
%with a choreographer and a sound expert to create a new grammar of expressive
%motions, combined with a novel modality based on \emph{soundscapes}: sound
%landscapes that the robot can modulate to influence the mood of the social
%environment (calm, excited, worried, etc.).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%

%
%
%%The four research questions previously listed are addressed across five
%%work-packages: \textbf{WP1} is dedicated to the conceptual framing of the
%%project (R1) and the identification of interaction principles; \textbf{WP2}
%%extracts from these principles the set of requirements in term of
%%socio-cognitive capabilities for the robot (R3), and implement them; in parallel
%%to WP2,  \textbf{WP3} looks at how social robots can generate congruent social
%%behaviours (R3); \textbf{WP4} transposes the conceptual framework of WP1 into a
%%principled cognitive architecture and integrates together the cognitive
%%functions of WP2 and WP3 (R2);and \textbf{WP5} organises the experimental
%%fieldwork that demonstrates the \project approach in ambitious and complementary
%%real-world situations (R4).
%
%
%
%Figure~\ref{fig:wps} gives an overview of the project
%work packages and their interrelations. Experimental fieldwork, which plays a central role in the
%project, appears in the centre of the figure.
%
%%The first important field
%%deployment is a one-year experiment, taking place at the Bristol science centre
%%(T1.1). This `public-in-the-loop' experiment is analysed and lead to the
%%definition of core interaction principles (T1.2). These are in turn translated
%%into algorithmic models, guiding the social teleology of the cognitive
%%architecture (T4.1).
%%
%%This first experiment is immediately followed by two other long-term
%%experimental deployments: a one-year deployment in one of Bristol's Special
%%Education Need (SEN) school (T5.1), followed by a one-year deployment at
%%Bristol's Children's hospital (T5.2). These two additional experiments are both
%%inputs for WP2 and WP3, and demonstrator for the robot socio-cognitive
%%architecture (WP4).
%%
%%Specifically, work package WP2 research, develop, and integrate all the components
%%pertaining to the assessment of the spatio-temporal and social environment of
%%the robot. Reference interaction situations and the data required to support
%%this work package is directly drawn from the experimental fieldwork that will
%%take place at the same time in WP1 and WP5. The perceptual capabilities
%%delivered by WP2 are continuously integrated into the robot's cognitive
%%architecture (T4.3), iteratively improving the socio-cognitive performances of
%%the robot.
%%
%%work package WP3 looks into behaviour generation using machine learning (T3.2)
%%and non-verbal affective modalities (T3.3). T3.2 is data-intensive, and will use
%%datasets acquired during the field deployments (T1.1, T5.1, T5.2), as well as
%%lab-recorded dataset of social interactions. Similar to WP2, the capabilities
%%built in WP3 are integrated in the robot architecture in T4.3.
%%
%%In addition to the integration of WP2 and WP3 capabilities, WP4 is also
%%researching and developing the socio-cognitive drives of the architecture. They
%%come both from T1.2 (as previously mentioned), and
%%human-in-the-loop/public-in-the-loop machine learning (T4.2). T4.2, in
%%particular, is tighly connected to the experimental fieldwork, where the
%%learning-from-end-users take place.
%
%%\subsection{Integration sprints}
%%
%%\project is a complex project, with numerous interdependencies between tasks.
%%To ensure the interdependencies are properly understood, and support effective
%%integration of the outputs of each work package, I will organise every 6 months
%%\textbf{integration sprints} (see Gantt diagram). Integration sprints are
%%one-week long integration retreat during which the whole \project team gather
%%and work together to effectively implement and test on the robot the different
%%components. In addition to providing regular `check points' for the projects,
%%they also set a stable schedule to deliver project components.
%%
%%This methodology was adopted in a project the PI previously took part in (FP7
%%CHRIS project), and had proved at that time to be of great value to ensure
%%project-wide cohesion and steady progress.
%%
%%The three integration sprints taking place before the beginning of the
%%experimental deployments (display as orange circles on the Gantt chart) are of
%%particular importance, and will be extended to two weeks.
%
%\subsection{WP1: \textbf{\wpOne}}
%
%WP1 aims at establishing the conceptual and ethical framework around the idea of
%\emph{robot-supported human-human interactions}. It does so by co-creating
%patterns of interaction and norms with the general public, using a unique
%combination of ethnographic observations and `crowd-sourced' interaction
%patterns.
%
%\begin{framed}
%    \textbf{Main outcomes:} A theoretical framework for thinking about the role of
%    social robots and guidelines to inform policies for this (including ethical
%    implications); a set of operational and co-created interaction principles; a
%    large dataset of social human-robot interactions
%
%    \textbf{Timeframe:} \textbf{Y1-Y3}; one senior post-doctoral research
%    assistant (PD1) with background in the sociology of technology.
%\end{framed}
%
%
%\textbf{T1.1 -- Conceptual framing and ethics of robot-supported social
%interactions}
%
%
%The first task in WP1 is to research and define the conceptual framework around
%questions like: what role should social robots have? Where
%to set the boundaries of artificial social interactions? What do
%`ethical-by-design' and `responsible-by-design' mean in the context of social
%human-robot interactions? 
%
%Each of the field experiments (T1.2, T5.1. T5.2) will both \emph{build on} and
%\emph{feed into} the framework developed in this task. In addition, four
%two-day workshops with the \project Ethics Advisory Board, spread over the
%duration of the project, will act as milestones for ethics review.
%
%\textbf{T1.2 -- Crowd-sourced patterns of robot-supported social
%interactions} The conceptual framework identified in T1.1 is translated
%into a set of \emph{interaction design principles} and \emph{determinants} that
%will together form a set of requirements and objectives for the socio-cognitive
%capabilities and architecture developed in WP2 and WP4.
%
%In order to anchor T1.2 in the reality and complexity of human social
%interactions and involve the public in the design of these patterns and norms, I
%will embed one \project robot in the Bristol Science Centre WeTheCurious for a
%whole year (Y2). With the help of a researcher (PDRA), the visitors will be guided in
%tele-operating the robot to assist other visitors, and, by doing so, co-design
%what defines a good robot helper. This will generate the quantitative and
%qualitative data to inform questions like `what role for the robot?', `when to
%intervene?' and `what are effective and acceptable social influence
%techniques?'. It will also be a unique example of crowd-sourcing at a large
%scale, with the general public, the design of the interactions with social
%robots. The generated dataset will also be used as a data source in WP2 and
%WP3.
%
%\textbf{Specific resources} The Bristol Science Centre is fully committed to the
%project. They will include \project in its official programme of activities, and
%provide in-kind training for the \project researcher based at the centre.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% WeTheCurious
%% 
%% - one robot completelty controlled by children, one by adults
%% 
%% what to learn?
%% 
%% - when to approach? when to prompt? [example of the salesman/museum facilitator]
%% - when is the right time to help/intervene or not? 'child being told off by
%% parents -> not the right time!'
%% - group interactions -> when to intervene? what about peer-pressure? eg what if
%% I tell off one child in front of another?
%% - break the barrier for participation. Japanese Journal paper -> facilitating students questions
%% - impact on moral norms? what behaviours is acceptable?
%% - what role for the robot? another mediator? a peer?
%% - what can we do with that 'alien creature'
%% 
%% - robot taking one child to talk to the museum mediators ("I, robot, am  shy!
%% would you come with me?")
%% 
%% - learning how to adjust behaviour based on personality
%% - 'why do I behave like that with that person, and like this with that other
%% person?'
%% 
%% - reinforcement learning instead of human-in-the-loop -> what reinforcement
%% signal? engagement
%% 
%% - the robot that 'take sides': take side against the adults? -> bending in its
%% role?
%% 
%% 
%% - social embarassment
%% - space for pretence: the robot can adopt an 'artificial role' as long as it is
%% possible (accpetable/...) to pretend the robot is
%
%
%
%\subsection{WP2: \textbf{\wpTwo}}
%
%
%In WP2, the project addresses the key scientific and technical prerequisites to
%effectively deliver WP4's cognitive architecture: namely, the perception and modeling of
%the spatio-temporal and social environment of the robot. This includes spatial
%characteristics (proxemics; group dynamics; complex, dynamic attentional
%mechanisms); psycho-social determinants (social roles and hierarchies; social
%groups; mental modelling; anthropomorphic ascriptions), and temporal characteristics
%(effects of novelty; dynamics of anthropomorphism and mental ascriptions; group
%dynamics). I have investigated many of these socio-cognitive capabilities in
%isolation (Table~\ref{pi-expertise}), and this WP is about
%\emph{integrating} them into a coherent perceptual subsystem, significantly
%extending the state of the art\parencite{lemaignan2017artificial}\textsuperscript{,}\parencite{baxter2016cognitive}.
%
%\begin{framed}
%    \textbf{Main outcomes:} A complete pipeline for spatio-temporal and social
%    situation assessment, built as open-source ROS nodes and able to map in
%    real time the physical and social environment of the robot.
%
%    \textbf{Timeframe:} \textbf{Y1-Y4}; one post-doctoral research assistat (PD2) in social
%signal processing/machine learning/cognitive modelling expertise.
%\end{framed}
%
%\textbf{T2.1 -- Hybrid situation assessment and knowledge representation} This
%task builds the foundational spatio-temporal and symbolic perception and
%representation system for the robot. It will integrate the state of the art in
%spatio-temporal situation assessment that I have previously
%developed\parencite{lemaignan2018underworlds}\parencite{sallami2019simulation},
%drawing on recent
%advances in data-driven semantic labelling (for instance, using 4D convolution
%nets like MinkowskiNet\parencite{choy20194d}), and a symbolic knowledge base (like
%my own ontology-based one\parencite{lemaignan2010oro}) in order to create a coherent
%system of representations for the cognitive architecture of the robot.
%
%\textbf{T2.2 -- Multi-modal human model} This task focuses on the processing and
%modelling of social signals, extending existing techniques both
%model-based\parencite{gunes2017automatic}\textsuperscript{,}\parencite{lemaignan2016realtime} and
%data-driven\parencite{bartlett2019what}. This task goes beyond the
%state of the art by looking specifically at resolving highly dynamical signals
%(like gaze saccades and micro facial expressions). Required datasets will be
%drawn from my previous work\parencite{lemaignan2018pinsoro}, as well as from
%the project experiments (T1.2, T5.1, T5.2).
%
%\textbf{T2.3 -- Interaction and group dynamics} Building on T2.2, T2.3
%investigates the automatic understanding and modelling of group-level social
%interactions\parencite{tapus2019perceiving}, including
%$f$-formations\parencite{marshall2011using},
%sociograms\parencite{garcia2016hybrid}, and inter-personal
%affordances\parencite{pandey2013affordance}. This task builds on literature on
%social dynamics analysis
%(eg\parencite{durantin2017social}\textsuperscript{,}\parencite{jermann2009physical}\textsuperscript{,}\parencite{martinez2019collocated})
%to apply it to real-time social assessment by a robot, which is itself embedded
%in the interaction.
%
%\textbf{T2.4 -- Integrated model of the social environment} The integration of
%the social cues from T2.2 and T2.3 results in a socio-cognitive model of the
%social environment of the robot, which will effectively extend the representation
%capabilities of T2.1 to the social sphere. The result of T2.4 is an AI module
%that implements a full social assessment pipeline, from social signal perception
%to higher-level socio-cognitive constructs. T2.4 also includes a
%focused experimental programme (based on the protocols designed by Frith and
%Happ√©\parencite{frith1994autism}, which I introduce in\parencite{lemaignan2015mutual}) to
%demonstrate in isolation the resulting socio-cognitive capabilities.
%
%
%\subsection{WP3: \textbf{\wpThree}} 
%
%Mirroring WP2's focus on understanding the social interactions, WP3 addresses the
%question of social behaviour \emph{production}: how to create natural,
%non-repetitive behaviours, engaging end-users over a sustained period of time. The robot
%behaviours will be exclusively non-verbal (non-verbal utterances, gaze, joint
%attention, facial expressions and expressive motions), and will include
%soundscapes as a novel, non-verbal interaction modality.
%
%\begin{framed}
%
%    \textbf{Main outcomes:} A new method to automatically design complex and
%    non-repetitive social behaviours, with a focus on non-verbal communication;
%    research on soundscapes as a novel non-verbal modality for human-robot
%    interaction.
%
%    \textbf{Timeframe:} \textbf{Y2-Y5}; one post-doctoral research assistant (PD3) in machine learning/learning from
%demonstration.
%
%\end{framed}
%
%\textbf{T3.1 -- Behavioural baseline} T3.1 establishes a baseline for behaviour
%generation, by surveying and implementing the current state of the art
%(behaviours library, activity switching\parencite{coninx2016towards}). This
%baseline will enable early in-situ experimental deployments, while also
%providing a comparison point for T3.2.
%
%\textbf{T3.2 -- Generative neural network for social behaviour production}
%\project aims to significantly advance the state of the art in this regard, by
%combining two recent techniques: (1) generative neural networks for affective
%robot motion
%generation\parencite{yang2019appgan}\textsuperscript{,}\parencite{marmpena2019generating}\textsuperscript{,}\parencite{suguitan2020moveae}
%(with training data created with an expert choreographer); (2) interactive
%machine learning in high-dimensional input/output spaces, where I have achieved
%with my students promising results for generating complex social
%behaviours\parencite{senft2019teaching}\textsuperscript{,}\parencite{winkle2020insitu}
%that fully involve the end-users\parencite{winkle2018social}. Modulating (1)
%with the learnt features of (2), I will target a breakthrough in generating robots' social
%behaviours: the generation of non-repetitive, socially congruent and
%transparent social behaviours (including gestures but also gazing behaviours and
%facial expressions).
%
%\textbf{T3.3 -- Non-verbal behaviours and robot soundscape} In task T3.3, we
%introduce a novel non-verbal interaction modality for robots, based on
%soundscapes. Soundscapes involve creating a sound environment that reflects a
%particular situation; they have also been shown to be an effective intervention
%technique in the context of special needs
%interventions\parencite{greher2010soundscape}. The soundscapes that I will
%create are `owned' by the robot, which can manipulate them itself, for example
%to create an approachable, non-threatening, non-judgmental, social interaction
%context, or make the interaction a trusted physical and emotional safe-space for
%the user.
%
%\textbf{Specific resource}: these soundscapes will be co-designed with Dr.
%Dave Meckin, an expert on sound design for vulnerable children, and a staff
%member at the host institution.
%
%\subsection{WP4: \textbf{\wpFour}}
%
%In WP4, I will design a novel socio-cognitive architecture for social
%robots and implement it on the Halodi EVE robot. WP4 will integrate the
%modeling capabilities and behaviour production developed in WP2 and WP3, with a
%dual action policy -- one driven by a social teleology (an artificial
%intrinsic motivation to act socially) and one learned through
%human-in-the-loop machine learning (Figure~\ref{fig:archi}). This WP is high-risk/high-gain: while sustaining
%long-term engagement in a principled way remains a major scientific
%challenge in social robotics\parencite{hoffman2019anki}, the WP adopts a very novel
%approach to goal-driven socio-cognitive architectures. It has the potential to
%unlock long-term social engagement by endowing the robot with its own
%intentionality\parencite{wiese2017robots}, while maintaining human oversight.
%
%\begin{figure}[h!]
%\centering
%\includegraphics[width=0.8\linewidth]{archi.pdf}
%\caption{Overview of the AI engine implemented in \project.}
%\label{fig:archi}
%\end{figure}
%
%
%\begin{oframed}
%    \textbf{Main outcomes:} An integrated cognitive architecture for social
%    robots, driven by both long-term social goals, and machine-learnt action
%    policies; a reference open-source implementation, enabling long-term
%    autonomy for the Halodi EVE robot.
%
%    \textbf{Timeframe:} \textbf{Y1-Y5}; one post-doctoral research assistant (PD4) in cognitive
%    robotics; one PhD student (PHD1).
%
%\end{oframed}
%
%\textbf{T4.1 -- A social teleology for robots} The idea of a \emph{teleological}
%(ie goal-driven) robot architecture for social interaction is highly novel
%(existing literature on teleological robots only focuses on simple cognitive
%systems\parencite{oudeyer2005playground}\textsuperscript{,}\parencite{moulinfrier2014self})
%or virtual agents\parencite{pathak2017curiosity}.This task will design and
%implement such an architecture on the EVE robot. It first identifies
%\emph{interaction principles} from the interaction patterns and determinants
%uncovered in T1.2; these are then mapped into \emph{long-term interaction
%goals}, capable of driving the robot actions over a period of time.
%
%\textbf{T4.2 -- Learning from humans to achieve `by-design' responsible \&
%trustworthy AI} Building on my recent results on human-in-the-loop social
%learning\parencite{senft2017supervised}\textsuperscript{,}\parencite{senft2019teaching}\textsuperscript{,}\parencite{winkle2020insitu},
%this task implements the mechanics to allow human end-users to progressively
%teach the robot a domain-specific social policy.  It also qualitatively
%researches how human-in-the-loop machine learning enables a more trustworthy AI
%system by involving end-users in the creation of the robot behaviours,
%resulting in \emph{explainable} behaviours for the end-users.
%
%\textbf{T4.3 -- Integrating a socially-driven architecture for long-term
%interaction} Building on my previous work on cognitive
%architecture\parencite{lemaignan2017artificial}, this task brings together, in
%a principled manner, the perceptual (WP2) and behavioural (WP3) capabilities of
%the robot, as well as the social policies created in T4.1 and T4.2. T4.3 will
%specifically look at long term autonomy, including long-term social goals,
%cognitive redundancy and behavioural complexity.
%
%T4.3 will also develop the arbitration mechanism that combines the robot's
%social teleology (T4.1) with the human-taught action policy (T4.2). This
%arbitration mechanism will build on research on reinforcement learning for
%experience transfer\parencite{madden2004transfer} that enables the re-assessment of
%a policy (here, our intrinsic motivation) based on previous experience (here,
%the human-taught policy).
%
%\subsection{WP5: \textbf{\wpFive}}
%
%Finally, WP5 aims to convincingly demonstrate the importance and positive
%impact that socially-driven, socially-responsible robotics may have. The
%experimental work of \project will be organised around an ambitious long-term
%study, set in a complex, real-world environment, at a Special Educative
%Needs (SEN) school.
%
%This environment also put the project in the unique position of actually
%delivering high societal impact: I anticipate 250+ SEN-educated children will
%directly benefit from the project, exploring how robots can have a net social
%utility while being accepted as an effective tool by field practitioners. This
%deployment will take place within the strict ethical framework established in
%T1.1.
%
%\begin{oframed}
%
%    \textbf{Main outcomes:} One long-term deployment of a social robot in a
%    real-world, high impact environment, demonstrating long-term acceptance and
%    social utility; large (anonymous) datasets of complex, real-world
%    human-robot interactions.
%
%    \textbf{Timeframe:} \textbf{Y3-Y5}; one post-doctoral research assistant (PD4, shared with WP4).
%
%\end{oframed}
%
%\textbf{T5.1 -- A robot companion to support physical, mental and social
%well-being in SEN schools} This task aims to demonstrate robot-supported
%social interventions within Bristol's network of SEN schools.  During a one-year
%period (Y3), the robot will be based in schools, with interventions co-designed
%with the teachers, the parents and the students, both through preliminary
%focus groups and in-situ machine learning.\TODO{Add more/rephrase}
%
%The envisioned interventions include: initiating group games; asking students
%about their well-being; co-teaching material with teachers; fostering
%interactions between the children.
%
%\textbf{Specific resources:} The task will be supported by SEN researcher Dr.
%Nigel Newbutt, a staff member at the host institution, who has a long track
%record and on-going research partnerships with Bristol's special needs schools.
%I am currently collaborating with Dr. Newbutt on a pilot study which involve a
%non-autonomous (teleoperated) robot in the same SEN school.
%
%
%\textbf{T5.2 -- \TODO{is there a T5.2? Potentially add material from Robot4SEN
%proposal}}
%
%\textbf{Specific resources:}
%
%\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TWO PAGES FOR NON-TECHNICAL ASPECTS

\section{Risk/gain assessment; risk mitigations}\label{risks}

\textbf{Tasks 1.1, 1.2} develop a novel methodology, `public-in-the-loop' machine
learning, for large-scale co-design of social interactions with the public. If
successful, this will be of great value, well beyond the project. The
proposed experimental setup (science centre visitors `taking control' of the robot)
might however lead to interactions that are either too short or to artificial to
create meaningful, generalisable social interaction. In addition, the messy and
complex nature of the science centre environment is also currently beyond-state-of-the-art
in term of extracting the useful social features required to train a classifier.

However, the interaction principles that we want to uncover in T1.1 and T1.2
(and that are feeding into WP2 and WP4) will principally come from a qualitative
analysis of the interactions, carried in parallel to the machine learning
approach. This well within the expertise of the PI, and, as such, is low-risk.
T1.1 can thus be described as a \ul{\bf medium-risk, high-gain} component of
\project.

\vspace{1em}

\textbf{Task 2.1} develops a novel situation assessment component, that
integrates spatio-temporal modeling with knowledge representation. The resulting
component is beyond-state-of-the-art, and would be highly relevant to a large range
of robotic applications. This component relies on integrating tools that are
independently relatively mature and well understood, and the principles of the
integration itself is already well researched. Besides, it falls well within the
PI
expertise~\parencite{lemaignan2018underworlds,sallami2019simulation,lemaignan2010oro}.
As such, T2.1 can be described as \ul{\bf low-risk, medium-gain}.

\textbf{Tasks 2.2, 2.3, 2.4} Work on real-time modeling of social dynamics in
real-world environments are only begining to be studied in robotics. While the
underpinning are well understood in neighbouring academic fields, a very
significant work remain to be done to integrate disparate or partial approaches
into one framework. These tasks also require the acquisition of novel datasets
that focus on natural human-human social interactions. The PI has extensive
experience in building and acquiring such
datasets~\parencite{lemaignan2018pinsoro,sallami2020unexpected}, and does not
foreseen major difficulties. The resulting components have however the potential
to unlock a new class of social robots, aware in real-time of their social
surroundings and dynamics.  These tasks are thus considered \ul{\bf low-risk,
high-gain}.

\vspace{1em}

\textbf{Task 3.1} The behavioural baseline implements the current state-of-the-art,
and as such is \ul{\bf low-risk, low-gain}. T3.1 will guarantee early on in the
project a `working' robot, yet with predictable/repetitive behaviours.

\textbf{Task 3.2} The neural generation of complex social behaviours is a
\ul{\bf medium-risk, high-gain} task: while it builds on solid existing
state-of-the-art, it relies on very significant progress in both the modeling of the
social dynamics (WP2) and the capacity of designing a machine learning approach
to learn and generate these complex behaviours. While the former falls well
within the PI expertise, machine learning for social motion generation is
essentially a novel field. The success of this task will rely to a large
extend on the quality of the post-doctoral researcher recruited to lead this
effort. The main mitigation to the risk associated to T3.2 is the behavioural
baseline created in T3.1: the behavioural capabilities generated in T3.2 can be
complemented by ad-hoc behaviours whenever required.

\textbf{Task 3.3} Non-verbal communication is a well established subfield of HRI
research, well known to the PI. The creation of the novel interaction modality
based on soundscape is novel, with potential for impact beyond the project. This
new modality will be co-developped with an expert of sound design for
interaction, and we do not foresee major risks. Overall, the task is \ul{\bf
low-risk, medium-gain}.

\vspace{1em}

\textbf{Task 4.1} The conceptual framing of a \emph{socially-driven
architecture} (social teleology) and its translation into decision-making
algorithms are to a large extend open questions. This task might however lead to
uncover a fundamental mechanism to enable long-term engagement of users
with social robots. Building fundamentally on blue-sky research, this task is
\ul{\bf high-risk, high-gain}. If not successful, I will instead rely on the
decision-making strategy of T4.2, which is much lower risk.

\textbf{Task 4.2} The techniques developed in T4.2 have been previously used and
tested by the PI in two different real-world
environments~\parencite{senft2019teaching,winkle2020couch}. While they will require
significant adjustments for this project, the task is overall \ul{\bf low-risk,
low-gain}.

\textbf{Task 4.3} The integration of the different cognitive functions of the
robot into one principled cognitive architecture, that include cognitive
redundancy, is one of the core expertise of the
PI~\parencite{lemaignan2017artificial}. This task however includes significant novel
elements (cognitive mechanisms for long-term autonomy; decision arbitration)
that bear unknowns. Besides, this task is a critical pre-requisite for WP5. As a
result, T4.3 is considered as \ul{\bf high-risk}. The task is focused on
integration to meet the requirements of the WP5 experiments, and parts
of the resulting software architecture might be project-specific. However the
overall aims of endowing the robot with long-term social autonomy would be a
significant breakthrough, and as such, T4.3 is \ul{\bf high-gain}. The main
mitigations comes from (1) the iterative development process of the
architecture, that will start from the existing state-of-the-art, to which the
PI has previously contributed~\parencite{lemaignan2017artificial}. By doing so, a
decisional architecture for the robot will be available early on in the project.
While that architecture might be a scaled-down version of the initial ambition,
it will still enable the fieldwork proposed in WP5, possibly with a lesser level
of autonomy; (2) the possibility of using only one of the two action policies
(T4.1 \ul{or} T4.2), thus removing the need for complex arbitration.

\vspace{1em}

\textbf{WP5: Experimental deployments}

The two application scenarios (at the children hospital and in the SEN school)
are ambitious and inherently risky, as they target vulnerable populations.
However, first, demonstrating the importance of advanced social modelling, and
convincingly proving the effectiveness of our approach does require accordingly
complex social situations, and complex social dynamics. The two scenarios, which
complement each other, provide both.

Second, working with vulnerable populations, in constrained and complex
environments (children hospital and SEN schools) adds significant risks to the
project. But it is also what make the project in the unique position of
delivering a high societal impact: a direct positive impact on children's lives
(we anticipate 100+ hospitalised children and 50+ children with psycho-social
impairements interacting over long periods of time with a robot over the course
of the project), and a broader impact on the society, showing how robots can
have a lasting, strong, positive impact on the society, also establishing the
idea of \emph{robots supporting human interactions} instead of dehumanising our
social relationships.

\textbf{Together, Task 5.1 and 5.2 are \ul{high-risk, high-gain}.}

The two main mitigations are (1) early and continuous engagement with the
stakeholders, and (2) the decoupling of the two applications, meaning that the
risks associated to each of them do not impact the other one.

Early engagement will be ensured by relying on a participatory design
methodology, involving all the stakeholders from the onset of the project; the
methodology will involve regular joint workshops; on-site (hospital and SEN
schools) research stay including engagement with the staff/charities and the
children themselves; early field testing and prototyping, relying if necessary
on provisional, yet well-known, robot platforms available at the host
institution (for instance, Softbank Nao and Pepper). This user-centered approach
will be championed by the post-doc recruited on the project on WP4 and WP5, who will
have to have a strong expertise in user-centered design.

It is also important to note that, while preparing this bid, initial discussions
have been held with all the partners involved with the experimental fieldwork
(WeTheCurious science centre, Bristol's Children Hospital, the network of SEN
schools): each of these institutions is enthusiastic about the project, already
contributing ideas to integrate the robots in their daily routines, and
ready to dedicate time and effort for its success.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\newpage
%
%\section{Appendix: Current research grants and any on-going applications related
%to the proposal}
%
%\subsection{Current Grants}
%
%\begin{tabular}{p{1.8cm}p{1.8cm}llp{4cm}p{4cm}}
%\toprule
%\textbf{Project Title} & \textbf{Funding source} & \textbf{Amount} & \textbf{Period} & \textbf{Role of the PI} & \textbf{Relation to current  ERC proposal} \\ \midrule
%    CAPRI & InnovateUK (UK) & ‚Ç¨4 840 508 & 2017 -- 2020 & Co-I for BRL; driverless car simulation for safety verification & Dev. and verification of trustworthy autonomous systems \\ \midrule
%    ROBOPILOT & InnovateUK (UK) & ‚Ç¨7 986 981 & 2018 -- 2020 & Co-I for BRL; driverless car simulation for safety verification & Dev. and verification of trustworthy autonomous systems \\ \midrule
%    CAV Forth & InnovateUK (UK) & ‚Ç¨5 093 327 & 2019 -- 2021 & Co-I for BRL; supervising the safety case and simulation-based verification & Dev. and verification of trustworthy autonomous systems \\ \midrule
%    RoboClass & UWE (UK) & ‚Ç¨5 854 & 2019 -- 2020 & PI; project supervision and robot development & Classroom deployment of a social robot \\ \bottomrule
%\end{tabular}
%
%\subsection{On-going and submitted grant applications}
%
%\begin{tabular}{p{1.8cm}p{1.8cm}llp{4cm}p{4cm}}
%\toprule
%\textbf{Project Title} & \textbf{Funding source} & \textbf{Amount} & \textbf{Period} & \textbf{Role of the PI} & \textbf{Relation to current  ERC proposal} \\ \midrule
%    RoboPets & Amazon (US) & ‚Ç¨10 942 & 2020 -- 2020 & PI; project supervision and lead researcher & Learning and generation of continuous, congruent social behaviours \\ \midrule
%    ROBUST & EPSRC (UK) & ‚Ç¨761 124 & 2020 -- 2022 & PI; project supervision and
%    architecture implementation & Dev. of a redundant cognitive robot architecture for HRI \\ \midrule
%    HEROS & H2020 (EU) & ‚Ç¨7M & 2021 -- 2024 & Co-I for BRL; research
%    lead on cognitive architecture & Dev. of a redundant cognitive robot architecture for HRI \\ \midrule
%    Robots4SEN & UWE (UK) & ‚Ç¨29 274 & 2020 -- 2021 & PI; project supervision and robot development & Pilot deployment of a social robot in a SEN school \\ \bottomrule
%\end{tabular}
%



%


\newpage





%\subsection{Host institution}\label{host-institution}}
%
%The \emph{Bristol Robotics Laboratory (BRL)} is the largest co-located
%and most comprehensive advanced robotics research establishment in the
%UK. It is a joint venture between the University of the West of England
%and the University of Bristol. BRL's multidisciplinary approach aims to
%create autonomous devices capable of working independently, with each
%other, or with humans. BRL draws on robotics, electrical \& mechanical
%engineering, computer science, psychology, cognitive science and
%sociology. BRL has an international reputation as a leading research
%centre in advanced robotics research and has over 250 researchers
%working on a broad portfolio of topics: HRI, collective robotics, aerial
%robotics, neuro-inspired control, haptics, control systems, energy
%harvesting and self-sustaining systems, rehabilitation robotics, soft
%robotics and biomedical systems. BRL has many collaboration
%partnerships, both national and international, and is experienced in
%managing large multi-site projects. BRL has support from two embedded
%units specialising in business and enterprise, together with an
%incubator and successful track record of spin-outs.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\newpage
%\chapter{B2.a State-of-the-art and objectives}
%
%\eu{(B2.a, B2.b, B2.c: max 15 pages (2 pages for B2.c)}
%\eu{Specify the proposal objectives in the context of the state
%of the art in the research field. It should be clear how and why the proposed work is important for
%the field, and what impact it will have if successful, such as how it may open up new horizons or
%opportunities for science, technology or scholarship. Specify any particularly challenging or
%unconventional aspects of the proposal, including multi- or inter-disciplinary aspects.}
%
%\TODO{TARGET PAGE COUNT: 3 pages: state of art + vision; 2 pages: methodology overview; 5 pages:
%WPs; 3 pages: ethics + risks; 2 pages: resources}
%
%\TODO{as a reference: DECRESIM project: 4 pages on B2.a State of art and
%objectives; B2.b ~7 pages on WPs + 2 pages on risk assessment}
%
%
%
%\section{State of the art: real-world social robots and impact on the
%society}
%
%Social robotics is a disruptive field, with a profound impact on society and
%economy\parencite{williams2020social}. A recent report from the United Nations about
%the impact of the technological revolution on labour markets stated that AI and
%robotics are expected to radically change the labor market world-wide destroying
%some job categories and creating others\parencite{bruckner2017frontier}. Social
%robotics, however, is still an young, emerging, research-active field. The
%expectations are high, in multiple application domains: elderly care, customer
%service (in airports and shopping malls, for instance), education, child
%development, and autonomous vehicles to name a few\parencite{baillie2019challenges}.
%However, whereas both computer-based AI applications, and traditional industrial
%robots already have a significant economic impact, social robots have not
%reached that point yet. Significantly, the recent failures of several companies
%investing in social robotics, like Jibo, Kuri, Willow Garage and Anki, and the
%major setbacks of companies like SoftBank, who designed and deployed hundreds of
%Pepper robot in their shops, before renouncing a few months later due to the poor
%reception by the customers, show that these technologies are not yet
%mature\parencite{tulli2019great}.
%
%Indeed, understanding \emph{why} these robots have failed, is one of the
%active debate within the Human-Robot Interaction
%community\parencite{hoffman2019anki}, with only a handful of qualitative studies on
%this question\parencite{dereshev2019longterm,degraaf2017phased}. Proposed
%explanations include the lack of perceived usefulness (robot seen purely as a
%toy); the limited liveliness of the robot that become rapidly predictable and
%repetitive\parencite{lemaignan2014cognitive}; the poor management of expectations,
%where user over-ascribe cognitive capabilities that do not match the reality.
%The community agrees however that the crux of the issue is achieving long-term
%social engagement\parencite{yang2018grand,hoffman2019anki}
%
%Research is however seemingly hitting a wall to further progress towards
%socially meaningful long-term interactions. For instance, in their large review
%of research in robotics for education, Belpaeme et al.\parencite{belpaeme2018social}
%point to the shortcomings that prevent further development of effective,
%long-term social robotics in educative settings: the need for a correct
%interpretation of the social environment; the difficulty of action selection;
%the difficulty of pacing generated behaviours: three issues that underpin
%long-term engagement.
%
%Attempts at long-term human-robot interactions are nevertheless becoming more
%common\parencite{kunze2018artificial,leite2013social}, with a number of studies
%involving social robots deployed in real-world settings (for instance in
%schools\parencite{leite2014empathic,westlund2017measuring,
%lemaignan2016learning,coninx2016towards}, homes\parencite{degraaf2017phased} and
%care centres\parencite{hawes2017strands,winkle2020insitu}) over relatively long
%periods of time (up to 2 or 3 months at a time). Even though these robots are
%typically not fully autonomous, they do exhibit a level of autonomy, either by
%handling autonomously a relatively broad range of shallow tasks (eg, a
%butler-like robot answering simple questions, like in\parencite{hawes2017strands} or
%in the H2020 MuMMer\parencite{heikkila2018can} and FP7
%Spencer\parencite{triebel2016spencer} projects), or a narrow, well-specified complex
%task (for instance, supporting exercising in a gym, as I did in\parencite{winkle2020insitu}).
%However, general purpose, long-term interaction is still an open question.
%
%
%\subsection{Social robotics and vulnerable children}
%
%Application of social robotics to vulnerable children (either hospitalised or
%suffering cognitive and/or motor impairments) is an active field of research.
%This reflects both the measured efficacy of robot-based intervention, and the
%perceived need for additional support for these populations.  Several European
%projects have looked at these populations, for instance the FP7 Aliz-e and H2020
%DREAM projects: in Aliz-e, \parencite{baxter2011long,coninx2016towards} report on how
%a social robot can support long-term engagement with diabetic children in
%hospital (noting however the rather ``crude'' nature of the created social
%interactions, and the limited autonomy of the robot).
%
%A significant body of literature also exist on robotics and autism (see for
%instance review by Pennisi et al.\parencite{pennisi2016autism}). This specific
%domain has been a fruitful terrain to explore specific aspects of social
%cognition in robotics (for instance, related to the Theory of Mind or to the
%processing of emotions. See my review in\parencite{lemaignan2015mutual}). This
%research draws on the extensive prior research in experimental cognitive
%sciences on autism (for instance\parencite{baron1985does, frith1994autism}), and the
%focused experimental programme of WP2 will specifically draw from this body of
%prior work to evidence the newly developed social modeling capabilities of the
%robot.
%
%The experimental programme of \project will take place over two years, first in
%Special Education Needs schools (WP5.1), then in a paediatric ward at the
%Bristol's Children's Hospital (WP5.2). For both these studies, I will build on
%the experience learnt from previous studies in similar environments, with the
%novel contributions being both the very long-term interventions (one year each),
%and the user-centered methodology that I describe in the following sections.
%
%
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\section{\project aim and objectives: Responsible robots for long-term social engagement}
%
%%\begin{figure}
%%    \centering
%%    \includegraphics[width=0.9\linewidth]{figs/wizme+dolls}
%%    \caption{Early prototyping for the \project project: a pet-like robot that could
%%    mediate child-child interactions, and support group activities like active story-telling.}
%%    \label{early-prototype}
%%\end{figure}
%
%
%
%%
%%\begin{figure}
%%\centering
%%\includegraphics[width=0.9\linewidth]{figs/rHHI-1}
%%\caption{A child, just arriving in a new school, tries to integrate with other
%%    children -- in such a situation, should the robot decide to help to break the ice? What
%%    are the socio-cognitive peceptual and behavioural capabilities required to
%%    make that decision?}
%%\label{fig:rHHI}
%%\end{figure}
%%
%
%The overall aim of the \project project is to \textbf{create, sustain and better
%understand the dynamics of responsible long-term social human-robot
%interactions}.
%
%This broad aim translates in three key research questions that we seek to
%address over the course of the project:
%
%\paragraph{\bf RQ1:} what are the public expectations with respect to the role of social
%        robots? Can we collectively design principles ensuring safe, beneficial, socially
%        acceptable robots? 
%
%\paragraph{\bf RQ2:} what AI is required to sustain long-term engagement between end-users
%        and a robot? In particular, how to provide a robot with an understanding
%        of its own social environment? How to create behaviours that are not
%        repetitive or overly predictable?
%
%\paragraph{\bf RQ3:} what new ethical questions are raised by long-term social interaction
%        with an artificial agent? In particular, how to balance autonomy of the
%        robot with behaviour transparency and human oversight?
%
%\vspace{0.5em}
%\noindent The \project objectives are built around these three questions.
%
%\paragraph{\bf O1: conceptual framing} I will investigate the basic principles
%of responsible social interactions, that must form the foundations of a socially
%useful robot, accepted and used in the long run. I will answer questions like:
%What should motivate the robot to step in and attempt to help? What social norms
%are applicable to the robot behaviours? Using user-centred design and
%participatory design methodologies, I will identify the determinants and
%parameters of a responsible social intervention, performed by a socially-driven
%robot, and formalise them in guidelines. This objective aims at addressing RQ1,
%and is realised in WP1.
%
%\paragraph{\bf O2: real-time social modeling} I will significantly extend and integrate
%the current state-of-art in spatio-temporal modeling (so-called \emph{situation
%assessment}) with recent research in social state modeling, to create the novel
%cognitive capability of artificial \emph{social situation assessment}, enabling
%the robot to represent in real-time the social dynamics of its environment. This
%objective addresses one part of RQ2, and is investigated in WP2.
%
%
%\paragraph{\bf O3: congruent social behaviours production} Using the
%state-of-the-art in generative neural networks, combined with data acquired from
%an expert choreographer, I will create a novel way of producing non-repetitive,
%socially-congruent, expressive motions. This will be integrated with novel
%\emph{sound landscapes} to create a beyond-state-of-art, non-verbal yet highly
%expressive,  action and communication system for the robot. This objective
%addresses another part of RQ2, and is the focus of WP3.
%
%\paragraph{\bf O4: embodied AI breakthrough} I will integrate long-term social
%goals, arising from the interaction principles of \textbf{O1}, with the social
%modeling capability of \textbf{O2} and the behaviours production of \textbf{O3}
%into a principled, goal-driven cognitive architecture. The breakthrough will
%come from combining these long-term social goals with bottom-up action policies,
%designed and learnt from the end-users using human-in-the-loop reinforcement learning.
%This will result in robot behaviours that are perceived as purposeful and
%intentional (long-term goals), while being shaped by a
%user-created and user-controlled action policy.
%
%I will specifically test \ul{two hypotheses}: first, I hypothesise that long-term
%social goals, if suitably co-designed with the public and stakeholders, and
%properly integrated into the robot as a \emph{social teleology}, will create the
%perception that the robot is intentional and purposeful. This will in turn
%elicit sustained engagement from its human users.
%
%Second, I hypothesise that human-in-the-loop machine learning can be used to
%ensure an additional layer of human oversight and a level of behavioural
%transparency.  Human-in-the-loop reinforcement learning -- as implemented in the SPARC
%approach that I have developed and already used in complex social
%environments\parencite{senft2017supervised, senft2019teaching, winkle2020insitu} -- relies
%on a end-user `teacher', initially fully controlling the robot (teleoperation)
%while it learns the action policy, and then progressively relinquishing control
%up to a point where the robot is effectively autonomous. As argued
%in\parencite{senft2019teaching}, this approach leads to increased control and
%ownership of the system, and as a result, increased trust.
%
%This addresses RQ2 and RQ3; however it also raise an additional question: how to
%arbitrate between a top-down action policy arising from the long-term goals, and
%the bottom-up action policy learnt from the end-users? This question leads to
%objective {\bf O4'}: The design of a policy arbitration mechanism that preserve
%the robot's long-term intentional behaviour, while effectively guaranteeing human
%control, ownership and oversight. {\bf O4} and {\bf O4'} are addressed in WP4.
%
%\paragraph{\bf O5: ambitious field research} Finally, the last objective of the
%\project project is to demonstrate the effectiveness of my approach in complex,
%real world conditions. This means deploying the \project robots into existing
%social eco-systems that are sufficiently complex, yet open to explore novel
%social interactions. My objective is also to show that this real world
%deployment can be successfully driven by `end-to-end' involvement of all the
%end-users and stakeholders: from defining the robot role, from the different
%perspective of each of the end-users, to actually designing and `teaching' the
%robot what to do. This is the focus of WP5.
%
%
%\begin{framed}
%
%\noindent\bf Together, these five objectives build a coherent and realistic pathway towards
%addressing the overall aim of \project: creating, sustaining and better
%understanding the dynamics of responsible long-term social human-robot
%interactions.
%
%\end{framed}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\subsection{The case for robot-supported human-human interactions}
%%
%%This change of paradigm (rHHI) will have far reaching impact on the place that
%%we collectively assign to social robots in the society; it will help to
%%structure the public debate by providing the framework to look at human-robot
%%interactions in term of their net social utility.  As such, \textbf{the first
%%outcome of \project will be researching, defining and implementing the
%%conceptual framework that we need to ensure trustworthy and socially responsible
%%robots in our societies}.
%%
%%Indeed, in a time where robots are on the verge of becoming pervasive in our
%%daily human environment, can we ensure 'by design' that robots are to become
%%powerful tools to support more and better, positive interactions \emph{between
%%the people themselves}, and build a stronger, more cohesive society? Beyond
%%Human-Computer Interaction (HCI) and Human-Robot Interaction (HRI), \project is
%%a forward-looking, ground-breaking project that aims at establishing
%%\textbf{Robot-supported Human-Human Interactions (r-HHI)} as the next step
%%toward a Responsible AI: \textbf{the scientific investigation of how social
%%robots can create, shape and support strong, sustained, positive
%%\emph{human-human} relationships}.
%%
%%As a researcher who has been working for the last 12 years in the field of
%%human-robot interaction (and child-robot interaction in particular), I have been
%%a direct witness -- by being one of the architects -- of the crossing of a
%%critical milestone: the emergence of \textbf{long-term social interactions}
%%between robots and humans. Over the last two years in particular, we observe an
%%explosion of the number of studies involving social robots, deployed in
%%real-world settings (schools, care centres) over relatively long periods of time
%%(up to 2 or 3 months at a time)\parencite{kunze2018artificial,leite2013social}. Even
%%though these robots are rarely fully autonomous, they do already show high
%%levels of autonomy\parencite{senft2019teaching}, with full autonomy in
%%sight\parencite{hawes2017strands}.
%%
%%Due to the complex interplay between the socio-psychological determinants of the
%%interactions, the technical implementation, and the multiple ethical mechanisms
%%that have to be built-in the system, it is difficult to build one coherent and
%%consistent perspective on the whole question. Indeed, the conceptual,
%%intellectual framework emcompassing both the internal cognitive mechanisms
%%required by socially intelligent robots, as well as their role and impact in the
%%society, only exists in fragmented, disconnected pieces\parencite{citeneeded}.
%%
%%
%%The lack of such a proper conceptual framing is a critical issue: for robots to
%%have a positive impact on the society, with strict ethical and privacy-related
%%safeguarding, it is urgent that the wider academic and intellectual communities,
%%beyond technologists, embrace this question and build up the debate on the
%%acceptability of robots in our society. And \textbf{this also calls for a major
%%re-thinking of the traditional paradigm of Human-Robot Interaction}.
%%Tradionally, individual cognitive functions (like natural language processing,
%%emotion recognition, proxemics-aware navigation) are implemented in robots, with
%%the ill-supported assumption that 'the more available functions, the more
%%socially-capable the robot'. This assumption is questionable, and, at any rate,
%%does not address the 'why': why does the robot decides to do what it does? What
%%drives the behaviour of the robot? The case for \emph{teleological} (ie
%%goal-driven) robotic architectures has been made in the
%%past\parencite{wrede2012towards}, but only effectively realised for relatively
%%simple cognitive systems (like curiosity-driven robot
%%animals\parencite{oudeyer2005playground} or motor babbling in infant-like
%%robots\parencite{forestier2017unified}). However, socially-driven robots,
%%participating in complex interactions with humans, have been barely
%%investigated. We need to create a new social purpose, a new social teleology to
%%drive the development of social robots.  Indeed, \textbf{being socially-driven
%%to do 'good' is essential in ensuring trustworthy, socially responsible robots}.
%%Nutrured by decades of research in understanding human social cognition and its
%%social motivations, one of the key purpose of \project is to \textbf{research
%%and build a principled and socially-driven cognitive architecture} for
%%tomorrow's social robots. This socially-driven, teleological architecture,
%%intrinsically designed to \textbf{support stronger, positive human-human
%%interactions} is what underpins the concept of \emph{robot-supported human-human
%%interactions}.
%
%%\subsection{Key scientific challenges and research questions}
%%
%%Socially intelligent robots require unique, beyond state-of-the-art,
%%capabilities to \emph{(1)} understand the social interactions (social
%%situation awareness), \emph{(2)} autonomously decide the best course of action for
%%short-term and longer-term social influence, and \emph{(3)} perform the
%%appropriate social actions and exert said influence in an appropriate,
%%responsible manner.
%%Not only the required technology is itself beyond state-of-the-art (and will be
%%researched and integrated in WP2, WP4 and WP3), but the
%%interplay between technology, socio-cognitive psychology, privacy and ethics is
%%only starting to be researched and understood. \project offers an
%%strong vision and an ambitious, evidenced-based, methodology to significantly
%%advance our understanding of this multi-faceted problem.
%%
%%Over the course of 5 years, I will investigate hypotheses H1 and H2
%%by addressing the following research questions:
%%
%%\begin{itemize}
%%    \item \textbf{R1} [conceptual framing]: what are the basic principles of
%%        responsible social interactions, that must form the foundations of a
%%        socially useful robot, accepted and used in the long run? What should
%%        motivate the robot to step in and attempt to help? What are the
%%        determinants and parameters of a social intervention, performed by a
%%        socially-driven robot, to support positive human-human social
%%        interactions? How to balance social utility and social responsibility?
%%
%%    \item \textbf{R2} [implementation level]: how will these principles
%%        be integrated into a principled, socially-driven teleological
%%        architecture for autonomous robots? How this should be combined with
%%        bottom-up action policies, designed and learnt from the end-users? How
%%        can we ensure `by design' that the resulting AI will generate useful yet
%%        responsible, trustworthy, human-centered robot behaviour?
%%
%%    \item \textbf{R3} [technology level]: where are the technological gaps in
%%        artificial social modeling and cognition, that prevent the actual
%%        realisation of a robot capable of effective social support, sustained
%%        over long period of time? How can we fill them?
%%
%%    \item \textbf{R4} [experimental level]: can we demonstrate in complex, real
%%        world conditions, the effectiveness and usefulness of the
%%        robot-supported human-human interaction paradigm? Can we do so by
%%        involving the end-users at every stage of the design, implementation and
%%        testing cycle?
%%
%%\end{itemize}
%%
%%
%%
%%\project is also a highly technical project, who aims at significantly
%%pushing the state of the art in autonomous social robotics. Indeed, in \project, we will
%%\textbf{implement the AI required for robots to effectively support
%%human social interactions}.  In that sense, this research is also
%%ground-breaking in regards to its technical objectives. In \project, robots will
%%be able to understand complex social dynamics, and generate appropriate social
%%responses, in a fully autonomous way.  Extending the current line of research of
%%the PI, we will identify, implement, and integrate the a broad range of cognitive functions into a
%%principled, socially-driven, and trustworthy socio-cognitive architecture for
%%robots. This is the second major expected scientific outcome of \project.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%\section{Impact of the \project project}
%%\TODO{THIS SECTION IS STILL WORK-IN-PROGRESS}
%%
%%Academically, the \project project represents a timely combination of
%%very recent advances in supervised machine learning for social robot
%%behaviour with a creative and interdisciplinary approach to the design
%%and automation of social robot behaviour. 
%%We will publish \project results in interdisciplinary and high-profile
%%discipline-specific journals (eg. Science Robotics; Frontiers in AI and
%%Robotics; Transaction in Human-Robot Interaction) and conferences (eg. AAAI,
%%HRI, RSS).
%%
%%The dataset of social behaviours and social signals we will create and
%%distribute represents a one-in-a-kind resource for the human robot
%%interaction community, and the human data collection will be
%%transferable to research in other domains such as human-computer
%%interaction.
%%
%%As \project will be deployed in a living lab environment, there is
%%significant scope for public outreach/engagement and media coverage,
%%which we will work with the BRL's media manager to maximise.
%%
%%
%%\project aims at building unique European capacity to assert leadership in this
%%domain, and, beyond the specific deliverables of this 5-years project,
%%establishing the PI as a world-leader in goal-driven, socially-responsible
%%robotics.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\newpage
%
%{\let\clearpage\relax\chapter{B2.b Methodology}\label{research-methodology}} % prevent page break before chapter
%
%\eu{Describe the proposed methodology in detail including any key intermediate
%goals. Explain and justify the methodology in relation to the state of the art,
%and particularly novel or unconventional aspects addressing the
%'high-risk/high-gain' balance. Highlight any intermediate stages where results
%may require adjustments to the project planning. In case you ask that team
%members are engaged by another host institution their participation has to be
%fully justified by the scientific added value they bring to the project.}
%
%
%\section{work packages overview and interrelations}\label{work package-interrelations}
%
%
%The four research questions previously listed are addressed across five
%work-packages: \textbf{WP1} is dedicated to the conceptual framing of the
%project (R1) and the identification of interaction principles; \textbf{WP2}
%extracts from these principles the set of requirements in term of
%socio-cognitive capabilities for the robot (R3), and implement them; in parallel
%to WP2,  \textbf{WP3} looks at how social robots can generate congruent social
%behaviours (R3); \textbf{WP4} transposes the conceptual framework of WP1 into a
%principled cognitive architecture and integrates together the cognitive
%functions of WP2 and WP3 (R2);and \textbf{WP5} organises the experimental
%fieldwork that demonstrates the \project approach in ambitious and complementary
%real-world situations (R4).
%
%
%
%\begin{figure}[h!]
%\centering
%\includegraphics[width=\linewidth]{figs/wps}
%\caption{Overview of the work packages and tasks, and tasks inter-relations.}
%\label{fig:wps}
%\end{figure}
%
%More specifically, Figure~\ref{fig:wps} gives an overview of the project
%work packages, and their interrelations. Fieldwork plays a central role in the
%project, and appears in the centre of the figure. The first important field
%deployment is a one-year experiment, taking place at the Bristol science centre
%(T1.1). This `public-in-the-loop' experiment is analysed and lead to the
%definition of core interaction principles (T1.2). These are in turn translated
%into algorithmic models, guiding the social teleology of the cognitive
%architecture (T4.1).
%
%This first experiment is immediately followed by two other long-term
%experimental deployments: a one-year deployment in one of Bristol's Special
%Education Need (SEN) school (T5.1), followed by a one-year deployment at
%Bristol's Children's hospital (T5.2). These two additional experiments are both
%inputs for WP2 and WP3, and demonstrator for the robot socio-cognitive
%architecture (WP4).
%
%Specifically, work package WP2 research, develop, and integrate all the components
%pertaining to the assessment of the spatio-temporal and social environment of
%the robot. Reference interaction situations and the data required to support
%this work package is directly drawn from the experimental fieldwork that will
%take place at the same time in WP1 and WP5. The perceptual capabilities
%delivered by WP2 are continuously integrated into the robot's cognitive
%architecture (T4.3), iteratively improving the socio-cognitive performances of
%the robot.
%
%work package WP3 looks into behaviour generation using machine learning (T3.2)
%and non-verbal affective modalities (T3.3). T3.2 is data-intensive, and will use
%datasets acquired during the field deployments (T1.1, T5.1, T5.2), as well as
%lab-recorded dataset of social interactions. Similar to WP2, the capabilities
%built in WP3 are integrated in the robot architecture in T4.3.
%
%In addition to the integration of WP2 and WP3 capabilities, WP4 is also
%researching and developing the socio-cognitive drives of the architecture. They
%come both from T1.2 (as previously mentioned), and
%human-in-the-loop/public-in-the-loop machine learning (T4.2). T4.2, in
%particular, is tighly connected to the experimental fieldwork, where the
%learning-from-end-users take place.
%
%\subsection{Integration sprints}
%
%\project is a complex project, with numerous interdependencies between tasks.
%To ensure the interdependencies are properly understood, and support effective
%integration of the outputs of each work package, I will organise every 6 months
%\textbf{integration sprints} (see Gantt diagram). Integration sprints are
%one-week long integration retreat during which the whole \project team gather
%and work together to effectively implement and test on the robot the different
%components. In addition to providing regular `check points' for the projects,
%they also set a stable schedule to deliver project components.
%
%This methodology was adopted in a project the PI previously took part in (FP7
%CHRIS project), and had proved at that time to be of great value to ensure
%project-wide cohesion and steady progress.
%
%The three integration sprints taking place before the beginning of the
%experimental deployments (display as orange circles on the Gantt chart) are of
%particular importance, and will be extended to two weeks.
%

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Risk/gain assessment; risk mitigations}\label{risks}
%
%\textbf{Tasks 1.1, 1.2} develop a novel methodology, `public-in-the-loop' machine
%learning, for large-scale co-design of social interactions with the public. If
%successful, this will be of great value, well beyond the project. The
%proposed experimental setup (science centre visitors `taking control' of the robot)
%might however lead to interactions that are either too short or to artificial to
%create meaningful, generalisable social interaction. In addition, the messy and
%complex nature of the science centre environment is also currently beyond-state-of-the-art
%in term of extracting the useful social features required to train a classifier.
%
%However, the interaction principles that we want to uncover in T1.1 and T1.2
%(and that are feeding into WP2 and WP4) will principally come from a qualitative
%analysis of the interactions, carried in parallel to the machine learning
%approach. This well within the expertise of the PI, and, as such, is low-risk.
%T1.1 can thus be described as a \ul{\bf medium-risk, high-gain} component of
%\project.
%
%\vspace{1em}
%
%\textbf{Task 2.1} develops a novel situation assessment component, that
%integrates spatio-temporal modeling with knowledge representation. The resulting
%component is beyond-state-of-the-art, and would be highly relevant to a large range
%of robotic applications. This component relies on integrating tools that are
%independently relatively mature and well understood, and the principles of the
%integration itself is already well researched. Besides, it falls well within the
%PI
%expertise\parencite{lemaignan2018underworlds,sallami2019simulation,lemaignan2010oro}.
%As such, T2.1 can be described as \ul{\bf low-risk, medium-gain}.
%
%\textbf{Tasks 2.2, 2.3, 2.4} Work on real-time modeling of social dynamics in
%real-world environments are only begining to be studied in robotics. While the
%underpinning are well understood in neighbouring academic fields, a very
%significant work remain to be done to integrate disparate or partial approaches
%into one framework. These tasks also require the acquisition of novel datasets
%that focus on natural human-human social interactions. The PI has extensive
%experience in building and acquiring such
%datasets\parencite{lemaignan2018pinsoro,sallami2020unexpected}, and does not
%foreseen major difficulties. The resulting components have however the potential
%to unlock a new class of social robots, aware in real-time of their social
%surroundings and dynamics.  These tasks are thus considered \ul{\bf low-risk,
%high-gain}.
%
%\vspace{1em}
%
%\textbf{Task 3.1} The behavioural baseline implements the current state-of-the-art,
%and as such is \ul{\bf low-risk, low-gain}. T3.1 will guarantee early on in the
%project a `working' robot, yet with predictable/repetitive behaviours.
%
%\textbf{Task 3.2} The neural generation of complex social behaviours is a
%\ul{\bf medium-risk, high-gain} task: while it builds on solid existing
%state-of-the-art, it relies on very significant progress in both the modeling of the
%social dynamics (WP2) and the capacity of designing a machine learning approach
%to learn and generate these complex behaviours. While the former falls well
%within the PI expertise, machine learning for social motion generation is
%essentially a novel field. The success of this task will rely to a large
%extend on the quality of the post-doctoral researcher recruited to lead this
%effort. The main mitigation to the risk associated to T3.2 is the behavioural
%baseline created in T3.1: the behavioural capabilities generated in T3.2 can be
%complemented by ad-hoc behaviours whenever required.
%
%\textbf{Task 3.3} Non-verbal communication is a well established subfield of HRI
%research, well known to the PI. The creation of the novel interaction modality
%based on soundscape is novel, with potential for impact beyond the project. This
%new modality will be co-developped with an expert of sound design for
%interaction, and we do not foresee major risks. Overall, the task is \ul{\bf
%low-risk, medium-gain}.
%
%\vspace{1em}
%
%\textbf{Task 4.1} The conceptual framing of a \emph{socially-driven
%architecture} (social teleology) and its translation into decision-making
%algorithms are to a large extend open questions. This task might however lead to
%uncover a fundamental mechanism to enable long-term engagement of users
%with social robots. Building fundamentally on blue-sky research, this task is
%\ul{\bf high-risk, high-gain}. If not successful, I will instead rely on the
%decision-making strategy of T4.2, which is much lower risk.
%
%\textbf{Task 4.2} The techniques developed in T4.2 have been previously used and
%tested by the PI in two different real-world
%environments\parencite{senft2019teaching,winkle2020insitu}. While they will require
%significant adjustments for this project, the task is overall \ul{\bf low-risk,
%low-gain}.
%
%\textbf{Task 4.3} The integration of the different cognitive functions of the
%robot into one principled cognitive architecture, that include cognitive
%redundancy, is one of the core expertise of the
%PI\parencite{lemaignan2017artificial}. This task however includes significant novel
%elements (cognitive mechanisms for long-term autonomy; decision arbitration)
%that bear unknowns. Besides, this task is a critical pre-requisite for WP5. As a
%result, T4.3 is considered as \ul{\bf high-risk}. The task is focused on
%integration to meet the requirements of the WP5 experiments, and parts
%of the resulting software architecture might be project-specific. However the
%overall aims of endowing the robot with long-term social autonomy would be a
%significant breakthrough, and as such, T4.3 is \ul{\bf high-gain}. The main
%mitigations comes from (1) the iterative development process of the
%architecture, that will start from the existing state-of-the-art, to which the
%PI has previously contributed\parencite{lemaignan2017artificial}. By doing so, a
%decisional architecture for the robot will be available early on in the project.
%While that architecture might be a scaled-down version of the initial ambition,
%it will still enable the fieldwork proposed in WP5, possibly with a lesser level
%of autonomy; (2) the possibility of using only one of the two action policies
%(T4.1 \ul{or} T4.2), thus removing the need for complex arbitration.
%
%\vspace{1em}
%
%\textbf{WP5: Experimental deployments}
%
%The two application scenarios (at the children hospital and in the SEN school)
%are ambitious and inherently risky, as they target vulnerable populations.
%However, first, demonstrating the importance of advanced social modelling, and
%convincingly proving the effectiveness of our approach does require accordingly
%complex social situations, and complex social dynamics. The two scenarios, which
%complement each other, provide both.
%
%Second, working with vulnerable populations, in constrained and complex
%environments (children hospital and SEN schools) adds significant risks to the
%project. But it is also what make the project in the unique position of
%delivering a high societal impact: a direct positive impact on children's lives
%(we anticipate 100+ hospitalised children and 50+ children with psycho-social
%impairements interacting over long periods of time with a robot over the course
%of the project), and a broader impact on the society, showing how robots can
%have a lasting, strong, positive impact on the society, also establishing the
%idea of \emph{robots supporting human interactions} instead of dehumanising our
%social relationships.
%
%\textbf{Together, Task 5.1 and 5.2 are \ul{high-risk, high-gain}.}
%
%The two main mitigations are (1) early and continuous engagement with the
%stakeholders, and (2) the decoupling of the two applications, meaning that the
%risks associated to each of them do not impact the other one.
%
%Early engagement will be ensured by relying on a participatory design
%methodology, involving all the stakeholders from the onset of the project; the
%methodology will involve regular joint workshops; on-site (hospital and SEN
%schools) research stay including engagement with the staff/charities and the
%children themselves; early field testing and prototyping, relying if necessary
%on provisional, yet well-known, robot platforms available at the host
%institution (for instance, Softbank Nao and Pepper). This user-centered approach
%will be championed by the post-doc recruited on the project on WP4 and WP5, who will
%have to have a strong expertise in user-centered design.
%
%It is also important to note that, while preparing this bid, initial discussions
%have been held with all the partners involved with the experimental fieldwork
%(WeTheCurious science centre, Bristol's Children Hospital, the network of SEN
%schools): each of these institutions is enthusiastic about the project, already
%contributing ideas to integrate the robots in their daily routines, and
%ready to dedicate time and effort for its success.
%
%%
%%The PI, Pr. S√©verin Lemaignan, has been working for 12+
%%years in human-robot interaction, and over the last 6 years, specifically in the
%%field of child-robot interaction.  His profile is both highly technical, with
%%hundreds of hardware and software contributions to the worldwide robotic
%%community; and highly experimental, running dozens of studies and experiments
%%with children, including long-term ones, in multiple schools and in healthcare
%%environments. He is in a unique position to deliver both a scientific
%%breakthrough on social situation assessment for robots, and a high-impact
%%societal change.
%
%%\begin{table}[!htbp]
%%\caption{Identified risks and proposed mitigations}
%%\centering
%%\begin{tabular}{@{}llll@{}}
%%\toprule
%%    \textbf{Task} & \textbf{Description of risk}                 & \textbf{Level} & \textbf{Proposed risk mitigation measures} \\ \midrule
%%    T1.1          & Visitors' interactions with robot too short to create
%%    meaningful social interaction                            & High
%%    & The 'public-in-the-loop' machine learning methodology is high risk/high
%%    gain; machine                            \\
%%                  &                              &                &                            \\
%%                  &                              &                &                            \\
%%                  &                              &                &                            \\ \bottomrule
%%\end{tabular}
%%\end{table}
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
%\newpage



